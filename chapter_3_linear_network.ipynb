{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三章\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 第二章介绍了最为简单的深度学习网络：单层的线性神经网络，本质上这样的线性计算方式无法提供较为复杂的建模能力，但是一切复杂网络结构的基础，针对这类结构简单的线性网络，本章设计了两类任务：线性回归和softmax回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回归**是能为一个或多个自变量与因变量之间关系建模的一类方法。深度学习所解决的很多问题都可以建模为回归类型，**线性回归**作为最为简单和流行的回归类型，有几个基础的假设：线性回归中自变量和因变量之间的关系是线性的；另外，线性回归中允许观测值中包含一些噪声，这些噪声都比较正常，例如遵循正态分布。  \n",
    "书中给出的线性回归的例子是房价预测，此时因变量的房价会同时受到两个自变量房屋面积和房龄两个因素的影响，因此整体的数学模型可以表示为两个自变量的线性组合加上随机分布的噪声得到房价，如果将这个例子推广到高维情况，就可以得到线性回归的数学表达形式：  \n",
    "$$\n",
    "\\hat{y} = \\mathbf{w^T}\\mathbf{x} + b\n",
    "$$  \n",
    "在这个式子中，x和y对应着单个数据样本的特征和观测值，即x的维度就是特征的个数，但在深度学习的场景中，需要通过多个数据样本学习线性回归的模型，因此将上面的公式改写为如下形式：  \n",
    "$$\n",
    "\\mathbf{\\hat{y}} = \\mathbf{X}\\mathbf{w} + b\n",
    "$$  \n",
    "在这个式子中的$\\mathbf{X}$的每一行对应着一个数据样本，每一列对应着一个特征类型  \n",
    "此时我们再次回顾线性回归的出发点，我们的目标是寻找和识别一个符合这个线性回归模型的模式，因此问题的关键变成了如何寻找公式中的**权重矩阵** ，根据之前学过的一些知识，我们自然的想到了通过真实数据集确定一个最接近真实的权重矩阵，在寻找这样的模型参数之前，还需要引入两个概念：一种衡量模型参数学习质量的方式；一种能够更新模型参数以提高模型预测质量的方法  \n",
    "**损失函数**就是上面提到的模型质量的度量方式，针对特定的问题，需要设计符合当前问题的损失函数，通常将损失函数定义为数值越小损失越小，完美预测的损失为0。一种常见的损失函数就是平方损失函数：  \n",
    "$$\n",
    "L(\\mathbf{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}l^{(i)}(\\mathbf{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{2}(\\hat{y}^{(i)} - y^{(i)})^2 = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{2}(\\mathbf{w}^T\\mathbf{x}^{(i)} + b - y^{(i)})^2\n",
    "$$  \n",
    "上述公式中的$y^{(i)}$代表真实的标签数据，$\\hat{y}^{(i)}$代表预测的标签数据，在上述loss计算中共计n个数据样本，均值的损失函数设计从某种程度上代表了模型在整个数据集上的预测质量，因此我们可以通过上述损失函数寻找最符合预期的模型参数，即：  \n",
    "$$\n",
    "\\mathbf{w}^*, b^* = \\argmin_{\\mathbf{w},b} L(\\mathbf{w},b)\n",
    "$$  \n",
    "d2l书在这里提到了解析解的概念，其实这里不了解也没关系，如果硬要说的话，就是线性回归这样一个任务有解析解的形式，解析解的形式建立在$X$有列满秩的性质，即在众多的数据样本中的各种特征的分布是不同的，这个概念是显然的，因为如果整理数据必然不可能会出现不同特征的表现相同的情况，因此完全可以通过最小二乘解的唯一形式写出线性回归的解析解，但其实在考虑引入噪声的情况下，线性回归大概率是不存在解析解的  \n",
    "**优化策略**同样是学习最佳模型参数的一个重要层面，d2l在这里介绍的优化策略是最常见的一种优化算法——梯度下降、小批量随机梯度下降(minibatch stochastic gradient descent),这里我们选择和d2l书中不同的解释方式来说明这个优化算法的想法(不看公式)：在确定一个损失函数后，我们有一个很简单和很深刻的认知是：如果我们去计算损失函数关于这些模型参数的梯度，这个梯度的方向代表着在某一个优化位置的当前最佳优化方向(梯度向量的范数只能代表在单位变化下的函数变化情况)，如果让模型参数朝着相反着梯度的方向进行优化，理论上就可以让损失函数朝着当前的方向以最快速率下降，因此称为梯度下降，在单次迭代中，所有的数据样本都会参与梯度计算，整体的优化方向需要受到所有数据样本的影响，因此Pytorch中随机抽取一小批样本，在反向梯度的基础上乘以一个预先确定的学习率$\\eta$，这类似优化算法中的步长(另外在批次中反向梯度取均值)即为小批量随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00282 sec\n",
      "0.00019 sec\n"
     ]
    }
   ],
   "source": [
    "# 在正式开始介绍神经网络之前，d2l用一个小章节说明了在pytorch中通过tensor矢量化加速计算\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 这里设置两个1000维的向量进行加法运算\n",
    "ndim = 1000\n",
    "a = torch.ones(ndim)\n",
    "b = torch.ones(ndim)\n",
    "\n",
    "# 下面这个类借助time模块计算运算时长\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.time = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        self.tik = time.time()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.time.append(time.time()-self.tik)\n",
    "        return self.time[-1]\n",
    "    \n",
    "    def avg(self):\n",
    "        return sum(self.time) / len(self.time)\n",
    "    \n",
    "    def sum(self):\n",
    "        return sum(self.time)\n",
    "    \n",
    "    def cumsum(self):\n",
    "        return np.array(self.time).cumsum().tolist()\n",
    "    \n",
    "c = torch.zeros(ndim)\n",
    "timer = Timer()\n",
    "for i in range(ndim):\n",
    "    c[i] = a[i] + b[i]\n",
    "print(f'{timer.stop():.5f} sec') # 0.00812 sec\n",
    "\n",
    "timer.start()\n",
    "d = a + b \n",
    "print(f'{timer.stop():.5f} sec') # 0.00010 sec,计算时间大大缩短说明了矢量化计算的好处\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"302.08125pt\" height=\"183.35625pt\" viewBox=\"0 0 302.08125 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-10-04T10:06:49.829902</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.6, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 302.08125 183.35625 \n",
       "L 302.08125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 145.8 \n",
       "L 294.88125 145.8 \n",
       "L 294.88125 7.2 \n",
       "L 43.78125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 71.617385 145.8 \n",
       "L 71.617385 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m4dfb90c0e0\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"71.617385\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −6 -->\n",
       "      <g transform=\"translate(64.246291 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 104.462381 145.8 \n",
       "L 104.462381 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"104.462381\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −4 -->\n",
       "      <g transform=\"translate(97.091288 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 137.307378 145.8 \n",
       "L 137.307378 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"137.307378\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(129.936284 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 170.152375 145.8 \n",
       "L 170.152375 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"170.152375\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(166.971125 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 202.997372 145.8 \n",
       "L 202.997372 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"202.997372\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(199.816122 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 235.842368 145.8 \n",
       "L 235.842368 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"235.842368\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(232.661118 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 268.687365 145.8 \n",
       "L 268.687365 7.2 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4dfb90c0e0\" x=\"268.687365\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(265.506115 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- x -->\n",
       "     <g transform=\"translate(166.371875 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-78\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 43.78125 139.5 \n",
       "L 294.88125 139.5 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <defs>\n",
       "       <path id=\"mf11ee19824\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf11ee19824\" x=\"43.78125\" y=\"139.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(20.878125 143.299219) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 43.78125 107.916484 \n",
       "L 294.88125 107.916484 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf11ee19824\" x=\"43.78125\" y=\"107.916484\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.1 -->\n",
       "      <g transform=\"translate(20.878125 111.715702) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 43.78125 76.332967 \n",
       "L 294.88125 76.332967 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf11ee19824\" x=\"43.78125\" y=\"76.332967\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(20.878125 80.132186) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 43.78125 44.749451 \n",
       "L 294.88125 44.749451 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf11ee19824\" x=\"43.78125\" y=\"44.749451\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.3 -->\n",
       "      <g transform=\"translate(20.878125 48.54867) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 43.78125 13.165935 \n",
       "L 294.88125 13.165935 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf11ee19824\" x=\"43.78125\" y=\"13.165935\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(20.878125 16.965154) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- p(x) -->\n",
       "     <g transform=\"translate(14.798438 86.535156) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(63.476562 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" transform=\"translate(102.490234 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(161.669922 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path d=\"M 55.194886 139.5 \n",
       "L 107.746881 139.407793 \n",
       "L 112.673631 139.224376 \n",
       "L 115.95813 138.955952 \n",
       "L 119.24263 138.468224 \n",
       "L 122.52713 137.619981 \n",
       "L 124.169379 137.000022 \n",
       "L 125.811629 136.208702 \n",
       "L 127.453879 135.210021 \n",
       "L 129.096129 133.963946 \n",
       "L 130.738379 132.42702 \n",
       "L 132.380629 130.553325 \n",
       "L 134.022879 128.295876 \n",
       "L 135.665128 125.608434 \n",
       "L 137.307378 122.447754 \n",
       "L 138.949628 118.776218 \n",
       "L 140.591878 114.564764 \n",
       "L 142.234128 109.795994 \n",
       "L 143.876378 104.4673 \n",
       "L 145.518627 98.593789 \n",
       "L 147.160877 92.210802 \n",
       "L 150.445377 78.169216 \n",
       "L 158.656626 40.879228 \n",
       "L 160.298876 34.255953 \n",
       "L 161.941126 28.30539 \n",
       "L 163.583376 23.18734 \n",
       "L 165.225625 19.044317 \n",
       "L 166.867875 15.994967 \n",
       "L 168.510125 14.128428 \n",
       "L 170.152375 13.5 \n",
       "L 171.794625 14.128428 \n",
       "L 173.436875 15.994967 \n",
       "L 175.079124 19.044317 \n",
       "L 176.721374 23.18734 \n",
       "L 178.363624 28.30539 \n",
       "L 180.005874 34.255953 \n",
       "L 181.648124 40.879228 \n",
       "L 184.932623 55.460922 \n",
       "L 189.859373 78.169216 \n",
       "L 193.143873 92.210802 \n",
       "L 194.786122 98.593789 \n",
       "L 196.428372 104.4673 \n",
       "L 198.070622 109.795994 \n",
       "L 199.712872 114.564764 \n",
       "L 201.355122 118.776218 \n",
       "L 202.997372 122.447754 \n",
       "L 204.639621 125.608434 \n",
       "L 206.281871 128.295876 \n",
       "L 207.924121 130.553325 \n",
       "L 209.566371 132.42702 \n",
       "L 211.208621 133.963946 \n",
       "L 212.850871 135.210021 \n",
       "L 214.493121 136.208702 \n",
       "L 216.13537 137.000022 \n",
       "L 217.77762 137.619981 \n",
       "L 221.06212 138.468224 \n",
       "L 224.34662 138.955952 \n",
       "L 227.631119 139.224376 \n",
       "L 232.557869 139.407793 \n",
       "L 242.411368 139.492122 \n",
       "L 283.467614 139.5 \n",
       "L 283.467614 139.5 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_26\">\n",
       "    <path d=\"M 55.194886 139.362188 \n",
       "L 65.048385 139.123511 \n",
       "L 71.617385 138.800133 \n",
       "L 78.186384 138.250011 \n",
       "L 83.113134 137.618847 \n",
       "L 88.039883 136.731973 \n",
       "L 91.324383 135.96351 \n",
       "L 94.608882 135.026663 \n",
       "L 97.893382 133.897938 \n",
       "L 101.177882 132.554217 \n",
       "L 104.462381 130.973877 \n",
       "L 107.746881 129.138109 \n",
       "L 111.031381 127.032382 \n",
       "L 114.31588 124.647997 \n",
       "L 117.60038 121.98365 \n",
       "L 120.88488 119.046895 \n",
       "L 124.169379 115.855401 \n",
       "L 129.096129 110.656498 \n",
       "L 134.022879 105.097311 \n",
       "L 145.518627 91.945105 \n",
       "L 148.803127 88.496986 \n",
       "L 152.087627 85.343136 \n",
       "L 155.372126 82.566454 \n",
       "L 158.656626 80.242952 \n",
       "L 160.298876 79.272159 \n",
       "L 161.941126 78.438306 \n",
       "L 163.583376 77.747484 \n",
       "L 165.225625 77.204778 \n",
       "L 166.867875 76.814214 \n",
       "L 168.510125 76.578701 \n",
       "L 170.152375 76.5 \n",
       "L 171.794625 76.578701 \n",
       "L 173.436875 76.814214 \n",
       "L 175.079124 77.204778 \n",
       "L 176.721374 77.747484 \n",
       "L 178.363624 78.438306 \n",
       "L 180.005874 79.272159 \n",
       "L 181.648124 80.242952 \n",
       "L 184.932623 82.566454 \n",
       "L 188.217123 85.343136 \n",
       "L 191.501623 88.496986 \n",
       "L 194.786122 91.945105 \n",
       "L 199.712872 97.480461 \n",
       "L 211.208621 110.656498 \n",
       "L 216.13537 115.855401 \n",
       "L 219.41987 119.046895 \n",
       "L 222.70437 121.98365 \n",
       "L 225.988869 124.647997 \n",
       "L 229.273369 127.032382 \n",
       "L 232.557869 129.138109 \n",
       "L 235.842368 130.973877 \n",
       "L 239.126868 132.554217 \n",
       "L 242.411368 133.897938 \n",
       "L 245.695867 135.026663 \n",
       "L 248.980367 135.96351 \n",
       "L 252.264867 136.731973 \n",
       "L 257.191616 137.618847 \n",
       "L 262.118366 138.250011 \n",
       "L 268.687365 138.800133 \n",
       "L 275.256364 139.123511 \n",
       "L 283.467614 139.336037 \n",
       "L 283.467614 139.336037 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_27\">\n",
       "    <path d=\"M 55.194886 139.5 \n",
       "L 157.014376 139.407793 \n",
       "L 161.941126 139.224376 \n",
       "L 165.225625 138.955952 \n",
       "L 168.510125 138.468224 \n",
       "L 171.794625 137.619981 \n",
       "L 173.436875 137.000022 \n",
       "L 175.079124 136.208702 \n",
       "L 176.721374 135.210021 \n",
       "L 178.363624 133.963946 \n",
       "L 180.005874 132.42702 \n",
       "L 181.648124 130.553325 \n",
       "L 183.290374 128.295876 \n",
       "L 184.932623 125.608434 \n",
       "L 186.574873 122.447754 \n",
       "L 188.217123 118.776218 \n",
       "L 189.859373 114.564764 \n",
       "L 191.501623 109.795994 \n",
       "L 193.143873 104.4673 \n",
       "L 194.786122 98.593789 \n",
       "L 196.428372 92.210802 \n",
       "L 199.712872 78.169216 \n",
       "L 207.924121 40.879228 \n",
       "L 209.566371 34.255953 \n",
       "L 211.208621 28.30539 \n",
       "L 212.850871 23.18734 \n",
       "L 214.493121 19.044317 \n",
       "L 216.13537 15.994967 \n",
       "L 217.77762 14.128428 \n",
       "L 219.41987 13.5 \n",
       "L 221.06212 14.128428 \n",
       "L 222.70437 15.994967 \n",
       "L 224.34662 19.044317 \n",
       "L 225.988869 23.18734 \n",
       "L 227.631119 28.30539 \n",
       "L 229.273369 34.255953 \n",
       "L 230.915619 40.879228 \n",
       "L 234.200119 55.460922 \n",
       "L 239.126868 78.169216 \n",
       "L 242.411368 92.210802 \n",
       "L 244.053618 98.593789 \n",
       "L 245.695867 104.4673 \n",
       "L 247.338117 109.795994 \n",
       "L 248.980367 114.564764 \n",
       "L 250.622617 118.776218 \n",
       "L 252.264867 122.447754 \n",
       "L 253.907117 125.608434 \n",
       "L 255.549366 128.295876 \n",
       "L 257.191616 130.553325 \n",
       "L 258.833866 132.42702 \n",
       "L 260.476116 133.963946 \n",
       "L 262.118366 135.210021 \n",
       "L 263.760616 136.208702 \n",
       "L 265.402865 137.000022 \n",
       "L 267.045115 137.619981 \n",
       "L 270.329615 138.468224 \n",
       "L 273.614115 138.955952 \n",
       "L 276.898614 139.224376 \n",
       "L 281.825364 139.407793 \n",
       "L 283.467614 139.437258 \n",
       "L 283.467614 139.437258 \n",
       "\" clip-path=\"url(#pc3717acaee)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 145.8 \n",
       "L 43.78125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 294.88125 145.8 \n",
       "L 294.88125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 145.8 \n",
       "L 294.88125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 7.2 \n",
       "L 294.88125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 50.78125 59.234375 \n",
       "L 148.878125 59.234375 \n",
       "Q 150.878125 59.234375 150.878125 57.234375 \n",
       "L 150.878125 14.2 \n",
       "Q 150.878125 12.2 148.878125 12.2 \n",
       "L 50.78125 12.2 \n",
       "Q 48.78125 12.2 48.78125 14.2 \n",
       "L 48.78125 57.234375 \n",
       "Q 48.78125 59.234375 50.78125 59.234375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_28\">\n",
       "     <path d=\"M 52.78125 20.298438 \n",
       "L 62.78125 20.298438 \n",
       "L 72.78125 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- mean 0,std 1 -->\n",
       "     <g transform=\"translate(80.78125 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 256 \n",
       "L 897 -744 \n",
       "L 494 -744 \n",
       "L 750 256 \n",
       "L 750 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(97.412109 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(158.935547 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(220.214844 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(283.59375 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(315.380859 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(379.003906 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(410.791016 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(462.890625 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(502.099609 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(565.576172 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(597.363281 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_29\">\n",
       "     <path d=\"M 52.78125 34.976563 \n",
       "L 62.78125 34.976563 \n",
       "L 72.78125 34.976563 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- mean 0,std 2 -->\n",
       "     <g transform=\"translate(80.78125 38.476563) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(97.412109 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(158.935547 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(220.214844 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(283.59375 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(315.380859 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(379.003906 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(410.791016 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(462.890625 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(502.099609 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(565.576172 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(597.363281 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_30\">\n",
       "     <path d=\"M 52.78125 49.654688 \n",
       "L 62.78125 49.654688 \n",
       "L 72.78125 49.654688 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- mean 3,std 1 -->\n",
       "     <g transform=\"translate(80.78125 53.154688) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(97.412109 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(158.935547 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(220.214844 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(283.59375 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(315.380859 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(379.003906 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(410.791016 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(462.890625 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(502.099609 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(565.576172 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(597.363281 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc3717acaee\">\n",
       "   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 450x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 下面的内容可以帮助从数学角度分析平方损失函数为何能作为一类经典基础的损失函数类型\n",
    "# 将原生的数据定义为符合正态分布\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "def normal(x, mu, sigma):\n",
    "    p = 1 / math.sqrt(2 * math.pi * sigma ** 2)\n",
    "    return (p * np.exp(-0.5 * (x - mu)**2 / sigma ** 2 ))\n",
    "\n",
    "x = np.arange(-7,7,0.1) # 这里展开说说arange和linspace的不同，arange的用法是常见参数顺序：开始点，结束点(左闭右开)，间隔长度；linspace的用法是常见参数顺序：开始点，结束点(左闭右闭)，总点数(所有离散点的个数)\n",
    "params = [(0,1), (0,2), (3,1)]\n",
    "# 这里画图用到了之前定义的画图函数，我们只能把第二章的画图函数再定义一遍\n",
    "\n",
    "def use_display():\n",
    "    backend_inline.set_matplotlib_formats(\"svg\")\n",
    "# backend_inline是IPython库的一个模块，主要作用是控制matplotlib图表的显示方式，设置的\"svg\"是一种矢量图格式，svg是一种基于XML的矢量图形格式，与\"png\"等位图格式不同，矢量图形格式可以做到无损缩放，但渲染复杂图形时消耗资源更多\n",
    "\n",
    "\n",
    "def set_figsize(figsize = [3.5,2.5]):\n",
    "    use_display()\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "\n",
    "\n",
    "def set_axes(axes,xlabel,ylabel,xscale,yscale,xlim,ylim,legend=None):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.grid()\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "\n",
    "# 上述的所有格式设置都是为了下面的plot函数服务，plot函数考虑了这样几种情况：只有y轴方向的数据，这意味着x轴坐标可能不重要，默认赋值为[0,n-1];在相同的x轴取值下，同时画出多条函数曲线\n",
    "\n",
    "def plot(X, Y=None, xlabel=None, ylabel=None, xscale='linear', yscale='linear', xlim=None, ylim=None, fmts=('-','m--','g-.','r:'), figsize=(3.5,2.5), axes=None, legend=None):\n",
    "    # fmts中指定了四种绘图格式，默认的plot曲线颜色为蓝色，'-'也是默认格式，表示实线，‘--’表示虚线，‘-.’表示点划线，':'表示点线\n",
    "    if legend is None:\n",
    "        legend = []\n",
    "    \n",
    "    set_figsize(figsize)\n",
    "    axes = axes if axes else plt.gca() # 未指定特定的绘图axes就选择当前的axes\n",
    "\n",
    "    def has_oneaxis(x):\n",
    "        if hasattr(x,\"ndim\") and x.ndim == 1 or isinstance(x,list) and not hasattr(x[0],\"__len__\"):\n",
    "            return True\n",
    "    # 这里的函数判断了两类情况，首先如果不是普通的list，那指定ndim==1确定了只会是一维的计算单元；如果是list类型，则x[0]没有'__len__'使得也不会出现二维以上的多维情况\n",
    "\n",
    "    if has_oneaxis(X):\n",
    "        X = [X] # 不管在调用plot函数时有没有指定y，这样的操作都会在原来的x基础上再套一个[],使得原来一维的计算单元变成了[1,n]这样的结构，这样的主要原因是为了配合后面的多组同时绘制\n",
    "\n",
    "    if Y is None:\n",
    "        X, Y = [[]] * len(X), X # 主要是为了处理未指定Y的情况,首先会执行将X的值赋给Y，再将X设置为对应长度的[]，这里设置对应长度主要是为了配合zip的解包\n",
    "    elif has_oneaxis(Y):\n",
    "        Y = [Y]\n",
    "    if len(X) != len(Y):\n",
    "        X = X * len(Y)\n",
    "    axes.cla()\n",
    "\n",
    "    for x,y,fmt in zip(X,Y,fmts):\n",
    "        if len(x):\n",
    "            plt.plot(x,y,fmt)\n",
    "        else:\n",
    "            plt.plot(y,fmt)\n",
    "    \n",
    "    set_axes(axes,xlabel,ylabel,xscale,yscale,xlim,ylim,legend)\n",
    "\n",
    "\n",
    "plot(x,[normal(x,mu,sigma) for mu,sigma in params], xlabel='x', ylabel='p(x)', figsize = (4.5,2.5), legend=[f'mean {mu},std {std}' for mu,std in params])\n",
    "# 这里需要注意语法问题，在循环参数不是唯一参数的情况下，需要在循环参数的外部添加圆括号和方括号\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在对正态分布的数学形式有初步了解后，就可以对含有噪声的观测数据建模，观测数据的噪声服从均值为0的高斯分布，于是整个观测模型可以写成：  \n",
    "$$\n",
    "y = \\mathbf{w}^T\\mathbf{x} + b + \\epsilon , \\quad \\epsilon \\sim \\mathcal{N}(0,\\sigma^2)\n",
    "$$  \n",
    "不含噪声的部分作为均值存在，添加的噪声为观测数据提供方差，因此可以根据数据样本中的$\\mathbf{x}$计算关于观测数据$\\mathbf{x}$的概率分布，理论上来说，我们希望通过网络、损失函数和优化器计算得到对应的后验分布最大，即公式：  \n",
    "$$\n",
    "P(y|\\mathbf{x}) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y - \\mathbf{w}^T\\mathbf{x} - b)^2).\\\\\n",
    "P(\\mathbf{y}|\\mathbf{x}) = \\prod_{i=1}^np(y^{(i)}|\\mathbf{x}^{(i)})\n",
    "$$  \n",
    "上述公式的成立代表着模型服从了真实的数据分布，如果按照损失函数在优化过程中越来越小的原则，我们可以去优化$P(\\mathbf{y}|\\mathbf{x})$的负对数，这样同样将后验分布作为指导模型参数优化方向的损失函数，这样我们就能得到下面的优化目标：  \n",
    "$$\n",
    "-\\log{P(\\mathbf{y}|\\mathbf{x})} = \\sum{i=1}_n\\frac{1}{2}\\log(2\\pi\\sigma^2) + \\frac{1}{2\\sigma^2}(y^{(i)} - \\mathbf{w}^T\\mathbf{x} - b)^2.\n",
    "$$  \n",
    "我们可以略微对上述优化目标加以分析，首先模型的优化目标是线性回归中的线性计算参数($\\mathbf{w}$和$b$)，所以在上面的负对数优化目标中第一部分完全可以不关注，因为第一项跟这两项模型参数毫无关系，第二项的优化目标如果不考虑外面的系数，不就是我们之前一直在说的平方损失函数吗？至此，我们就得到了选择平方损失函数的理由，从概率分布上可以说明，当然平方损失函数的数学理解不应局限在高斯分布的假设当中，同时，其他的更加复杂的损失函数也可以用严密的数学方式证明其合理性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在正式进入神经网络的编写前需要了解一些预备知识：\n",
    "在我们的后面内容中，我们会涉及到神经网络在特定的上下文环境中运行，以及以什么样的模式来运行网络，常见的例子就是`with torch.no_grad():`和`model.train()`、`model.eval()`\n",
    "with torch.no_grad()常用于参数更新和推理阶段，它的作用是关闭梯度跟踪，在with torch.no_grad()上下文管理器下，PyTorch不会记录张量操作的计算图，也不会自动计算梯度，这样也能节省内存和计算资源，避免因保留不必要的中间变量而导致的内存占用：因此在参数更新的场景下，参数更新只是单纯的数值操作，我们并不想把他加入到计算图中；推理类似，我们只需要用，并不再需要进行复杂的计算和生成计算图，但这个场景下可以使用更加精确的：with torch.inference_mode():，因为这个上下文中还可以禁用一些内部机制\n",
    "model.eval()通常会和with.torch.no_grad():一起使用，这说明现在的网络处于评估模式，model.eval()通常发生在normalization和dropout中，为什么会有评估模式的出现呢：可以想象这两个方法的应用场景：batch normalization在训练的时候是根据单个batch中的数据来计算均值方差的，但在测试时只能去计算训练时总的均值和方差来等效替代测试数据中的这两项，再比如dropout中，训练时会随机地舍弃部分结点，但推理的时候就直接使用了所有的网络结点，也就是说，实际上测试模式和model.train()的出现会为了切换模型的行为  \n",
    "上述两种情况解决的是**逻辑问题**，但with torch.no_grad()解决的是当前的操作是否要加入计算图，是否占用计算资源，解决的是**资源问题**，与with torch.no_grad()对应的是with torch.enable_grad();因此这两者还是有本质的差别，甚至在model.eval()中也可以with torch.enable_grad():    \n",
    "推理时建议使用with torch.inference_mode():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epcoh 1, loss 0.02246\n",
      "epcoh 2, loss 0.00008\n",
      "epcoh 3, loss 0.00005\n",
      "w的估计误差:tensor([1.0061e-04, 2.2173e-05], grad_fn=<SubBackward0>)\n",
      "b的估计误差:-0.00017261505126953125\n",
      "真实的w和b:2.0、-3.4000000953674316、4.2; 训练得到的w和b:1.9998993873596191、-3.400022268295288、4.200172424316406\n"
     ]
    }
   ],
   "source": [
    "# 从下面开始，即将从零实现线性回归，一个线性回归预测模型包括数据流水线、模型、损失函数、优化器等等，因此需要一部分一部分地去实现这些组件\n",
    "\n",
    "# 下面是生成数据集和读取数据集的模块\n",
    "import torch\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def synthetic_data(w,b,num_examples):\n",
    "    X = torch.randn((num_examples,len(w)))\n",
    "    y = torch.mv(X,w) + b \n",
    "    y += torch.randn_like(y) * 0.01\n",
    "    return X, y.reshape((-1,1))\n",
    "\n",
    "true_w = torch.tensor([2,-3.4])\n",
    "true_b = 4.2\n",
    "num_examples = 1000\n",
    "features, labels = synthetic_data(true_w,true_b,num_examples)\n",
    "# plt.scatter(features[:,0].numpy(),labels.numpy(),1) # 1在这里表示的是散点图中散点的大小\n",
    "\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = features.shape[0]\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0,num_examples,batch_size):\n",
    "        # 这里转不转换成torch.tensor类型的索引都可以\n",
    "        chosen_indices = indices[i:min(i+batch_size,num_examples)]\n",
    "        # batch_indices = torch.tensor(chosen_indices)\n",
    "        yield features[chosen_indices],labels[chosen_indices]\n",
    "        # yield features[batch_indices], labels[batch_indices] \n",
    "\n",
    "# 下面是模型定义和模型参数初始化\n",
    "w = torch.normal(0,0.01,(2,1),requires_grad=True)\n",
    "b = torch.zeros((),requires_grad=True)\n",
    "\n",
    "def linreg(X,w,b):\n",
    "    return torch.mm(X,w) + b\n",
    "\n",
    "# 下面是损失函数定义，需要注意在labels和计算得到的估计labels之间有维度的差别(labels的形状为(n,1))：\n",
    "def squared_loss(y_hat,y):\n",
    "    '''y_hat一般为预测值,y一般为真实值'''\n",
    "    return (y.reshape(y_hat.shape) - y_hat) ** 2 / 2\n",
    "\n",
    "# 下面是优化算法，采用的仍然是小批量随机梯度下降算法指导模型参数的优化方向；\n",
    "def sgd(batch_size,lr,params):\n",
    "    with torch.no_grad(): # 根据前面对这几个上下文的分析\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_() #单次更新后需要清空梯度，tensor默认的梯度计算方式为累积\n",
    "\n",
    "# 截止目前为止，几个组件都已经定义好，可以正式开始训练了：\n",
    "batch_size = 10\n",
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter(batch_size,features,labels):\n",
    "        y_hat = net(X,w,b)\n",
    "        l = loss(y_hat,y)\n",
    "        l.sum().backward()\n",
    "        sgd(batch_size,lr,(w,b))\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features,w,b),labels)\n",
    "        print(f'epcoh {epoch + 1}, loss {float(train_l.mean()):.5f}')\n",
    "\n",
    "# 我们可以查看一下w和b训练的效果，通过查看true_w和true_b之间的差距：\n",
    "print(f\"w的估计误差:{true_w - w.reshape(true_w.shape)}\")\n",
    "print(f\"b的估计误差:{true_b - b}\")\n",
    "print(f'真实的w和b:{true_w[0].item()}、{true_w[1].item()}、{true_b}; 训练得到的w和b:{w[0].item()}、{w[1].item()}、{b.item()}')\n",
    "\n",
    "# 在读取数据的函数之中，有一个基础的python语法：迭代器和生成器，生成器可以看成是一个定义生成器的函数+一个迭代使用的场景，本质上和迭代器没有太大的差别，yield会不断产生需要的迭代元素完成输出任务，在读取数据的场景中，数据集需要按照batch_size进行批量大小的输出，并且在单次迭代过程中是“要一点给一点”，这就完美符合生成器的特性,下面给一个示例代码展示生成器：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# for content in read_number(nested_list):\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     print(content)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m nested_list:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m part_inside \u001b[38;5;129;01min\u001b[39;00m part:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(part_inside)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# 这里的这个例子说明的是生成器的运行方式，yield的逻辑很好理解，即每次调用每次都运行到yield之前\n",
    "# 生成器函数调用时不会立即执行，而是返回一个生成器对象，生成器本身属于特殊的迭代器，因此可以在循环或next()中自动迭代\n",
    "# 当第一次调用next()，生成器函数会从头开始执行，直到遇到第一个yield语句，yield会将一个值返回给调用方，同时暂停函数的执行状态\n",
    "# 后续调用next()时，生成器函数每次都会从之前暂停的地方继续执行，直到遇到下一个yield\n",
    "# 当没有更多的yield可供执行时，会抛出StopIteration异常\n",
    "\n",
    "print(issubclass(StopIteration, Exception))  # True\n",
    "print(issubclass(StopIteration, TypeError))  # False\n",
    "\n",
    "def read_number(num_list):\n",
    "    '''这个例子中使用了递归和生成器 最终也是想说明一件事 他可以按照我们的需求进行随取随停'''\n",
    "    try:\n",
    "        for part in num_list:\n",
    "            for part_inside in read_number(part):\n",
    "                yield part_inside\n",
    "    except TypeError: # 这里之所以用TypeError的错误类型，是因为如果读到int类型了即不可再分的情况下，就会出现int类无法迭代的错误(这属于TypeError)\n",
    "        yield num_list\n",
    "\n",
    "nested_list = [1, [2, [3, 4], 5], [6, 7], 8]\n",
    "\n",
    "# for content in read_number(nested_list):\n",
    "#     print(content)\n",
    "\n",
    "for part in nested_list:\n",
    "    for part_inside in part:\n",
    "        print(part_inside)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.8514, -3.6649],\n",
      "        [-6.8514, -3.6649],\n",
      "        [ 2.4225, -1.3884],\n",
      "        [-6.8514, -3.6649],\n",
      "        [ 4.5759, -4.8484],\n",
      "        [-1.4693,  0.9054],\n",
      "        [-5.6717, -2.3983],\n",
      "        [-4.2401,  5.4154],\n",
      "        [ 2.4225, -1.3884],\n",
      "        [-1.4693,  0.9054]])\n",
      "tensor([[ -2.0363],\n",
      "        [ -2.0363],\n",
      "        [  9.9762],\n",
      "        [ -2.0363],\n",
      "        [ 27.9778],\n",
      "        [ -6.3348],\n",
      "        [ -5.0970],\n",
      "        [-28.2437],\n",
      "        [  9.9762],\n",
      "        [ -6.3348]])\n"
     ]
    }
   ],
   "source": [
    "# 同样的实现流程，在现代的深度学习框架帮助之下，我们完全没有必要通过自己手写所有网络组件，运用pytorch中的一些封装好的函数和类，可以减少很多书写内容\n",
    "\n",
    "import random\n",
    "\n",
    "def data_iter(batch_size,features,labels):\n",
    "    total_num = len(features)\n",
    "    rank = torch.arange(total_num)\n",
    "    random.shuffle(rank)\n",
    "\n",
    "    for i in range(0,total_num,batch_size):\n",
    "        select_part = torch.arange(i,min(i+batch_size,total_num))\n",
    "        yield features[rank[select_part]],labels[rank[select_part]]\n",
    "    \n",
    "for x,y in data_iter(10,feature,label):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w = torch.tensor([1.0,1.0],requires_grad = True) #在定义tensor的内容时使用浮点数\n",
    "init_b = torch.ones((),requires_grad=True)\n",
    "\n",
    "def loss(y_hat,y):\n",
    "    return (y_hat.reshape(y.shape) - y) ** 2 / 2 #一定不要把形状搞错了 这就是广播机制需要熟悉的原因\n",
    "\n",
    "def net(x,w,b):\n",
    "    return torch.mv(x,w) + b\n",
    "\n",
    "def sgd(paras,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for para in paras:\n",
    "            para -= lr * para.grad / batch_size\n",
    "            para.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration is 1 tensor([ 2.5177, -3.3797], requires_grad=True) tensor(1.1686, requires_grad=True) loss is 0.5577819347381592\n",
      "iteration is 2 tensor([ 2.5110, -3.4149], requires_grad=True) tensor(1.1062, requires_grad=True) loss is 0.5545547604560852\n",
      "iteration is 3 tensor([ 2.4789, -3.4254], requires_grad=True) tensor(1.0484, requires_grad=True) loss is 0.5611150860786438\n",
      "iteration is 4 tensor([ 2.5529, -3.3691], requires_grad=True) tensor(1.0025, requires_grad=True) loss is 0.5770998001098633\n",
      "iteration is 5 tensor([ 2.5374, -3.3464], requires_grad=True) tensor(0.9931, requires_grad=True) loss is 0.5746312141418457\n",
      "iteration is 6 tensor([ 2.5191, -3.4204], requires_grad=True) tensor(1.0238, requires_grad=True) loss is 0.5554414987564087\n",
      "iteration is 7 tensor([ 2.5131, -3.4073], requires_grad=True) tensor(1.0230, requires_grad=True) loss is 0.5439419150352478\n",
      "iteration is 8 tensor([ 2.5142, -3.3458], requires_grad=True) tensor(0.9512, requires_grad=True) loss is 0.5624077320098877\n",
      "iteration is 9 tensor([ 2.4995, -3.3703], requires_grad=True) tensor(0.9890, requires_grad=True) loss is 0.5413716435432434\n",
      "iteration is 10 tensor([ 2.4996, -3.4157], requires_grad=True) tensor(0.9755, requires_grad=True) loss is 0.5454209446907043\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "lr = 0.01\n",
    "batch_size = 10\n",
    "# 数据集中有500组数据\n",
    "# 真实的w和b的大小为[2.5，-3.4]、1\n",
    "\n",
    "for i in range(iterations):\n",
    "    for x,y in data_iter(batch_size,feature,label):\n",
    "        l = loss(net(x,init_w,init_b),y)\n",
    "        l.sum().backward() #最后一步得化成标量\n",
    "        sgd([init_w,init_b],lr,batch_size)\n",
    "    with torch.no_grad():\n",
    "        loss_eval = loss(net(feature,init_w,init_b),label)\n",
    "        print(f\"iteration is {i+1}\",init_w,init_b,f\"loss is {torch.mean(loss_eval)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在手动写了所有的网络组件后，实际上没有必要每次都自己写这些组件，现有的深度学习框架已经很好地将这些功能封装了起来，回想一下我们之前实现一个简单的线性回归网络包括了哪些步骤：定义(找到数据集)、做一个数据集读取器、网络内容定义、损失函数定义、训练器定义和网络训练的代码，这些部分中有一些还是要像之前那样写的，但是网络的组件都可以通过调用现成的模块来实现\n",
    "开始之前提示一下从头写线性回归网络的注意点，因为在调用现成的模块快速实现网络构建时通常会省略这些容易出错的地方，需要自己注意：\n",
    "* backward()之前loss一定要是一个标量\n",
    "* 注意predicition数据和本身的label数据的形状要一致，否则广播机制会造成错误\n",
    "* 在评估的部分和参数更新的时候需要with torch.no_grad():定义一个不需要计算图的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1:the loss is 3.02561\n",
      "epoch2:the loss is 0.40678\n",
      "epoch3:the loss is 0.05637\n",
      "epoch4:the loss is 0.00807\n",
      "epoch5:the loss is 0.00124\n",
      "epoch6:the loss is 0.00027\n",
      "epoch7:the loss is 0.00012\n",
      "epoch8:the loss is 0.00010\n",
      "epoch9:the loss is 0.00010\n",
      "epoch10:the loss is 0.00010\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "\n",
    "def syn_data(w,b,data_len):\n",
    "    x = torch.normal(0,1,(data_len,len(w)))\n",
    "    y = torch.mv(x,w) + b\n",
    "    y -= torch.normal(0,0.01,y.shape)\n",
    "    return x,y.reshape(-1,1)\n",
    "\n",
    "true_w = torch.tensor([3.5,-2.4])\n",
    "true_b = torch.tensor(-2.3)\n",
    "data_len = 500\n",
    "\n",
    "features,labels = syn_data(true_w,true_b,data_len)\n",
    "\n",
    "def array_list(origin_data,batch_size,is_train):\n",
    "    dataset = data.TensorDataset(*origin_data)\n",
    "    return data.DataLoader(dataset,batch_size,shuffle=is_train)\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 10\n",
    "num_epoch = 10\n",
    "is_train = True\n",
    "net = nn.Sequential(nn.Linear(2,1))\n",
    "loss = nn.MSELoss()\n",
    "trainer = torch.optim.SGD(net.parameters(),lr)\n",
    "\n",
    "net[0].weight.data.normal_(0,1)\n",
    "net[0].bias.data.fill_(0)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    for x,y in array_list((features,labels),batch_size,is_train):\n",
    "        trainer.zero_grad()\n",
    "        l = loss(net(x),y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    with torch.no_grad():\n",
    "        loss_total = loss(net(features),labels)\n",
    "        print(f\"epoch{i+1}:\"+f\"the loss is {loss_total:.5f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从线性回归过渡到softmax回归，其中一个最大的区别就是输出的不同，在线性回归的例子当中，无论输入数据的维度如何，最终只输出一个符合线性计算的标量，也即一个值；但softmax不一样，网络会输出多个值，每个值对应分类的概率，因此当面对选择分类种类的问题时，将问题可以转换为多个输出值的网络，通过比较多个输出值的大小来确定最终输出的类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始之前，需要一定的信息论的知识，如果在这里有一定的理解难度需要自己去看一些信息论的入门书籍，比如为什么我们会定义熵，理论上来说熵是衡量一件事的信息量的单位，也是存储某个信息的最小存储长度，在后面的定义中，对数的底数被限制在2\n",
    "如果使用多个输出来确定最终的分类目标，我们必须解决两个问题，一个是输出的值不受控制，他并不一定是符合概率分布的0-1之间的值，另一个是在分类任务中我们应该使用什么样的损失函数来训练网络\n",
    "前面的这个问题可以由softmax解决，softmax的作用就是将一个处在大范围变动的值映射到0-1之间的概率，既然网络最终输出的是概率值，最终就能直接通过比较概率的大小来确定最终的分类输出结果\n",
    "第二个问题其实和第一个问题是相关的，在最终的输出经过一次softmax变换之后，等价于最终我们应该训练的是概率最接近于真实分类尽可能大、错误分类的概率尽可能小的情况，也就是说：我们最终希望去拟合一个分布，这时信息论的知识就再次出场了，我们希望衡量真实分布和训练分布的差距，就想到了一个工具：交叉熵(cross entropy),交叉熵和相对熵这两个概念都实际上说明了两个概率分布的接近程度；在这里值得多说一句的是，可以从相对熵的角度来推导交叉熵，也就可以理解为什么真实分布在算概率的部分，训练分布在算对数的部分了，从原理上理解的话：训练分布希望靠近真实分布，不能把因果关系搞错了\n",
    "d2l中在这一节值得阅读的部分在109页的softmax导数部分，为什么要使用指数归一化的方式处理概率，在这里就有很好的说明，求导数能本质上说明训练交叉熵就是在希望softmax后的结果接近真实分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([12, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAELCAYAAAAiFru1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAe25JREFUeJztnQeYFdX5/+f2u3crLLvA0kEQQQRFULErimIvUePPWGLU2KImMTExibEkRo01sUTzV6MmmqiJFUs09oIIqEhTeodd2H739vk/7+id97xn79x7d9mFLd/P8+yzZ+6ZOzN3Tpkzc77zfV2maZoGAAAAAAAAwBG3cxYAAAAAAACAwKAZAAAAAACAHGDQDAAAAAAAQA4waAYAAAAAACAHGDQDAAAAAACQAwyaAQAAAAAAyAEGzQAAAAAAAOQAg2YAAAAAAABygEEzAAAAAAAA3XXQPHz4cOPYY4/NuZ7L5TJ++9vfdth+aXuXXXZZh20PdC6PPvqoVWaffvppznUPOeQQ6w90H1C+3Qvqi6m8AEDb7d7ltmrVKvszlE83GDT3NjZs2GBdcD777DOjJ/Phhx9av7Ours7oyixatMg6TrXjALlB+QLQPUHbBSA3GDR3oUHz9ddf3ysGzfQ7d0bH/Prrr1t/+XbMdJzomNsGyheA7gnaLgC5waAZ9Br8fr/1l41IJGKkUqkddkyg40D5dn3o3FMZAKCCtgu6S5/SIYPm1atXG5dccomx6667GgUFBUZ5ebnxne98p9WdYFor88EHHxg//vGPjYqKCqOwsNA46aSTjOrq6pz7+dvf/mZ4vV7j6quvzrre+vXrje9///tG//79jUAgYIwfP954+OGH2/Sb/v73v1u/JxgMGpMnTzbefffdVuvMnz/fOProo42SkhKjqKjIOPzww42PP/641XorVqywzkffvn2NUChk7LvvvsbLL79s57/99tvGlClTrPR5551nnSP6o/PVk6AptXTZjRgxwv6d2Z4YPPXUU9b5Ly4uts7zhAkTjLvvvrvVetFoNGed0nVZdN5p/7SPX/3qV8agQYOs8rnnnnus8iIOPfRQ+zhpfeAMyrd38f7771v9FvWRo0aNMv7yl784viNC/Sn1w9Qfv/rqq23qp//0pz9ZeVR2ffr0Mfbee2/jH//4h53f2NhoXHnlldZ7MLSdyspK44gjjjDmzZvXyWeg54C22/3fI1iyZIlx2mmnWWVBY7ArrrjCHkxSOTqNKdr7XtiWLVuM888/32q/1AdMnDjRGqOlicfj1piHxjQ6DQ0N1nd++tOfinpy3XXXGbvssovVjocMGWL87Gc/sz7Pt0/ZEXg7YiNz5syxpnbOOOMMY/DgwVYB3X///VYjoKkUquwql19+udX50Qmide+66y7rJPzzn/903MeDDz5o/PCHPzR++ctfGjfddJPjeps3b7YGpekTSw31lVdesQqXCoo611y888471rH86Ec/sgrkvvvuM4466ijjk08+MXbffXdrnYULFxoHHnigVUGpYH0+n3XRoN9M399nn33s45k2bZoRDoet7VFlpop1/PHHG88884zVgey2227GDTfcYPzmN78xLrzwQmu7BH2vJ3HyyScbX331lfHkk08ad955p9GvXz/rcyqjTPz3v/81vvvd71o3I7fccov12eLFi62bLuoQtrdOpbnxxhutpxzUgKmBHnnkkVZZUQdN9Y3Kh0j/B5lB+fYeFixYYJ1HKlu64CYSCats6AKq87///c/417/+ZZUX1Qka3ObbTz/00ENWWZ166qn2IOCLL74wZs+ebZx55pnWOnRdoL6UtjNu3Dhj69at1oCe6tJee+21w89NdwRtt/tDA2ZqWzfffLP18I7OUW1trfHYY491+L5aWlqssc6yZcussqQbraeffto499xzLXkP1QEaE9H45t///rc1NlJnEp577jmrPGnMmH5aTGMiarc0BqLypD6G6iLVS1o/V5+ywzA7gHA43Oqzjz76yKTNP/bYY/ZnjzzyiPXZ9OnTzVQqZX9+1VVXmR6Px6yrq7M/GzZsmHnMMcdY6bvvvtt0uVzmjTfe2Go/tL3rrrvOXj7//PPNgQMHmjU1NWK9M844wywtLc14rPr26O/TTz+1P1u9erUZDAbNk046yf7sxBNPNP1+v7l8+XL7sw0bNpjFxcXmQQcdZH925ZVXWtt777337M8aGxvNESNGmMOHDzeTyaT12Zw5c6z16Bz1ZG677Tbrd65cuTLnuldccYVZUlJiJhIJx3XaUqcOPvhg6y/NW2+9ZX135MiRrerF008/beXROiB/UL69A+r/qE+kvjHNokWLrDJRLyuUdrvd5sKFC8X38+2nTzjhBHP8+PFZj4XWv/TSSzvol/Ve0Ha7JzT+ofNx/PHHi88vueQS6/PPP//cKlOn8YU+hkqXm1oP9PK56667rHWeeOIJ+7NYLGbut99+ZlFRkdnQ0GB99tprr1nrvfjii2KfM2fOtMo2zeOPP271E+o4iXjggQes73/wwQc5+5QdRYfIM0iSoT6Spzt9esReVlaWcYqM7iRUWyJ6sppMJi2Zh86tt95q3bXQ3SxN02SDzuezzz5rHHfccVa6pqbG/psxY4ZRX1+f15TdfvvtZ007pRk6dKhxwgknGK+99pp1nPRHLy2ceOKJxsiRI+31Bg4caD39oLslelpCzJo1y5g6dapxwAEH2OuRlIPOAd1105N4kBmqP83NzdZTjVy0pU7pnHPOOaIOgx0Dyrd7Qued+kLq/6hvTENPh6if1Tn44IOtJ8Dt6aepjqxbt86azXSC1qEnz/QyNdgxoO12PS699NJWT/jTY5COZtasWcaAAQOs2YY09GSZZgGampqs2XbisMMOs54Eq7MK9PSb6s3pp59uf0ZPqan/GDt2rOgP6PvEW2+9lbVP2ZG4O+pRPUkLSINCcgY6STStQ4/pqQPUUTtagqZu0idThU78z3/+c+svl46ZIJ0U7ZOkHLR/9S+tqyEdTi5Gjx7d6rMxY8ZYEgvaB/1RmjTPOlTwNNWwdu1aa5k6Bqf10vm9nW3bthmbNm2y/9J1hnTydN5JN06yH9I/OmmX8q1TmaCpJdB5oHx7FtT/UZ+fqZ/M1Nfp578t/TT1/fSQgR480P5oYEASAP3Bypdffmldf2g9kovQeyRg+0Hb7T7o7ZHeM3C73Z3iMrJ69Wprf7T9bOMaegftlFNOMZ5//nlbm0xyDXq4qg6av/76a0vyqvcHVMcyjdt2Zr3okEEz3dH87ne/szQ1pDOhp7B0J0H63Uxvu3o8nozb+ebJO0Mib+qEH3/8cWPlypU5jyO9r7POOsvaf6a//fffv92/E3Seno6e0qf/0po4eqGHLPheeOEFS+9Ed5vUSdPTh/bWqUzgSUbngvLt3ejnvy39NF2Ely5dar0QRrN19ISa/pM+Ng1dd2iQTC8MVlVVGbfddpt17SCNNNg+0Ha7L+rTfaeAQ/TEv7M544wzrJd10+2Rxoj0RJleHFT7BHqR1Kk/oJu0rlIvOuRFQHoJgxrL7bffbn9GL2xsr98jPbGmbVMnSS8ckOyBOkUn6M6E3uSlijB9+vR275fuenRIjE4vNKZfjKA0deY69AYr3X3RUw9i2LBhjuul84neEkUr0++keqM+dVDLmF4eoGlc+qOGRY2HXir49a9/bUmAduRxgtygfHs+1AfSRStTP5mpr9vefpocF+ipFP3FYjFrIEcPaX7xi19Yb+ATNKCjukN/9FSKXgCkdWggB/IDbbd7Q+1RfQJLL+lRudBLcumn+/qYrL0z3cOGDbNeyKXtq0+b9XENcdBBB1ntkyQaNJajl/iuvfbaVk/FP//8c2uc19XLt0OeNNOdpH7XSHf9HXEXQ1M/b7zxhjUdSDZCpJfOdhw0FUBPI2i6TicfWzvio48+EtpnklrQ9AK9uUv7oD9K02fq1Ae9EU5WSFQxyFWDmDlzpuW6QdtMQ1owmpqkypzW5dCFgejq0Zi2l0y/k/TjdPFM/6XPiV7W1Dj32GMPK63b0OyI4wS5Qfn2fKj/I+0xvdG+Zs0a+3NyTyCtcz7fz7ef1usIDdSo/tD1hqZ46RqjSwDpKSgN7jq7DvU00Ha7N/fee2+rMRiRtsWlh5C6dS45g7WHmTNnWnIdVatMDjq0T5JTkeZYrRvkfvPiiy9aqgFaT5VmpGeLyIKS3HJ0aOxHY6auQoc8aT722GOtk1FaWmo1Khog0kCX5BkdAd21kuSDLE6os6Y7lfSgVOcPf/iDNVVElm8XXHCBdTyky6JBMB0TpXNBtnK0H9VyjqAoRGnI9o6mDWiATHfYpN2hu2zqMEhjl+aaa66xbHyo4tL2yLeQLOdIbkIXjfRdGt1p0csVDzzwgPUUhjoG+g09TdOVfsGS7jRp2oZeHqAnFemOUOUHP/iBVV70MgDdPNFdMTXKSZMmdbrFEO2DLu70AipdlKke0HHQBRk4g/LtHVBfSBpWeqmL+r/0BZNkEfQEKhf59tP0cIJeOCK5BtnZ0cD8z3/+s3HMMcdY/SQNnKju0EWZpnvpgk3fpxcH1ZlPkBu03e4NjSlIKkP2uDQGe+KJJyxjgrQMgsqM2h39J69zGkDTDHp7uPDCC63xDlnMzZ0713oASKoAet+ALAWpbarQIJnqB8mqSIah15Hvfe97lmyD7COpX6D2TjfE9OSaPqebcTrmLkFHWHDU1taa5513ntmvXz/LbmTGjBnmkiVLLNu4c845p5WVCdmrqaTtZVQLGdVyLs3s2bNtS7e0DY1ul0Js3rzZsiAaMmSI6fP5zAEDBpiHH364+eCDD+b8LbQ9+i5ZqYwePdoMBALmnnvumdHeZt68edZvpd8cCoXMQw891Pzwww9brUe2dKeeeqpZVlZm2TRNnTrVfOmll1qt9/zzz5vjxo0zvV5vj7afI+vAQYMGWbYx2SyOnnnmGfPII480KysrLXu/oUOHmhdddJG5cePGdtUpJ1sjsjDKxEMPPWTZ4qRttGBxlB8o397BO++8Y06ePNkqOzqPZA+Vtr/S+9NM5NNP/+Uvf7H6+/LycqsvHjVqlHn11Veb9fX1Vn40GrWWJ06caF0bCgsLrfR99923A85AzwNtt/uRbnNk+UjjDGoHffr0MS+77DKzpaXFXo/GTGT1SBaNtM5pp51mbtmypV2Wc+n2mx73UR2YMGGC45iFLAepndN2b7rppozrkGXdLbfcYllMUlun30D9y/XXX2+391x9yo7A9e1BAAAAAACAbgS5xdDMD8ma0kFpQBfXNAMAAAAAANCTwaAZAAAAAACAHGDQDAAAAAAAQA6gaQYAAAAAACAHeNIMAAAAAABAR/g0U9SXDRs2WN57XT1aS2+AJgcoLCUZ+Oux39sDyrfrgLLt2aB8ey4o254Nyrdnk2/55jVopoJNh4UGXQeKVEjG8tsLyrfrgbLt2aB8ey4o254Nyrd3l29eg+Z0dJcDjJmG1/B13NGBdpEw4sb7xqxWUXfaS4eWr3rHvD1y+cnfhGslyv6wUWQtemWMna74PCbyPFEZut0VS9nprRNCct2jODrkttVlIm/MravtdHJLfuHXe3zZthPv0EFiefl5vDzqb7JsE6vWdsg+Uwd8E9KX2DY2KPIqHv/cTps7ONRyTylf9zhugxsP7SPyyo7gMt1cJ39nv2cL7HTxhytEXmTSMLG8+jh+2nPalE9E3pYob/eTFyeIvKo7Zxs7g55Stjsbz0iuB8kV3A/vbLpU+epPptt5rdX75k1H8vIup38t8tY1ltrpzculH7Q7Jo8nWcLX4WMmygihLy/g9jrmGrmPVGPTjh9rtLF88xo0p6cOqGC9rt7TeLss39aPjprS6dDyFce0HRXZywMdX6FfZHkCnOf1ymkUT1IbNKd40Ozxy8GTJxSw0+4Cmed18z5dO7LOd+WybSdeN59nwh0MOuYZHXSMKaX+6OWungfTxfVjh9BDytftCWRsj9axFCrtKqbl+dSyl+3aq5SZ9d0CbtuBIvnb/D6/8/531jWqh5Ttzsaj1K0d2vd2p/JtdQztHDRr/a/aV+rXXW/K+XrpdsvjMQv4OuzX2q76Xa9L7iPVlvPQUWONNpYvXgQEAAAAAAAgB3k9aQYg72mRLNMkyUP2EsvLT+fqd/2h/xZ5EXOLnR7uk/KIyotesdOTAtqTyjbw/+oH2On4SI/Iu+Aklgl8EJX3lhfP/z+xPOgOvjt2ffBZu4+nJ+Hpw1P2a06Tur1LTphlp2uPKRR5C+qr7HRzXJZtc1w+lRhQ2GCnS30RkXdEn+fs9C/eO0XkuZJcD/s9+FEev6b30XDmvmJ50MXLxHJtNGynh/nq5Hej/CRpz8HrRN7lt79hp/cPynb1bFOJWG5OcXm/V7+ryFvTxPVr7LFfibyDz66103fOmS7yRp87VyyD1pR/wOd216LNIm9h40A73XSRnKJPLlya9z48u4yw06e8KNvgAN8SO/1y7SSRt+oI7hOSdfVGryJPOYJ3sJRcLP6Z1Ocevz+3gT7e5SJvc4yvtcVe2afePPgFOz1ij6Ksh9qU4u/OCvcXeYk9+Fpb8X6jPNYmviZ/+jFLwIhdb1spt7NJ1s0dBZ40AwAAAAAAkAMMmgEAAAAAAMgB5Bmg7WSZGvL0K7fTLU/KKZyLhz0rlv0ufllgVUxO9W2J8VTtl81yuilh8vROgVu6Z4wukFM262J97XRc+R6RMp0F/9dEKu10P598o/fq8f8Vy2WP8lT1dQuPE3kDTlxs9EaStTxF7q+X9eXJPxxtp/e7co7IO3fgB3b6wGCNyOvjke4nC2MtdnpVQjo4/GTed+x01Wuy3GPZZxZ7Le6Ju9np5tPk1PfcxSPkuqGEnXa5ZfmaKW5XaxLcHxDXNp/suP9ESj7DSSrtc1uDlPEkk7xuKiG/N3/uLnbaN5DbJvHVg1PE8pgLZf0DhhHwcNnuUyin748uYeeZAa9I55kVce6zv//+uSLv5YP/LJaDrvftdLXyghmxKMr9/bDgVpG3vE7WA9C67c58ks8tUV4vJRArmvha25KQL97Fk9xXNsekHO6ZhXva6VBh1LE9ErEYDy19Pvly/tC+fG1Y45X9dpGXt3v4gVzXiOopsuPe/Lf97HT5/9txMjs8aQYAAAAAACAHGDQDAAAAAACQAwyaAQAAAAAA6JWa5jZEivGUs+a1doa0OCn5x8d57cPllbogMy51tnmTzVS7AyLe7AhKnufjPKOc9anE7MZRYlnVGBd44iKvJcnn1O2Sv93vSjjmfdEs7c28im5ax5clT2VLTEYIqokXOWqjbxz/vMi7d6pid/bJAqM3kvLLeu2t44Ai7zwyVeT5vs9lsi0pz3Nfj9SWL46MttOPLpEWaf0f58hz9SOkprmgegcHNOkmfHU1W8WlauQ501F1zIGAbLuJBH83rumNV69hPaW7QV5+UkFZLi5FG236s5SZsp6Fl48tuVbq4Ct2kxrZ+rO43pQ+kaW/70V8XVdhp2Plsh7MaxlupycF14i8A4PcL48+Z57Iu2P2EWL56gGv2+kFEdlnF7pZ17qgUb7PYhjS3rBXkWUMUHszt8GP6uR1dmUDj3GIoDfh+F5PVNE0u7Rrq6pjjkZl200oGmbCq+iYi0PSuk7VUUeTXke7So9bXncLfXJctcv32eKw4d99HN+p6WjwpBkAAAAAAIAcYNAMAAAAAABAb5RnuDw8xWAmeCqCcE8aJ5YXX8RTwG52sLLwNfPUsbdFTg/6Xv80fzmGKuVQju2bD9x5bcfl5aJy0TSN/Fk7jcRhk8XyzHKWJ8xr5qk8IqTZwwWUH1Hp5+huxBGFbNVW5ZHTRD7lnDWm5IkIueX5jZopxzvEYjdb6oRTcop5RYLP9yuNe4i8cFJa8RjKDFfElFKdr37A001jPjF6Jb4mWX7hflwSJatl+c359d52+s0hUnIR6SenEktWcdkOqJFSm3AF14OU3stlUUH1ZoY9xues/nLZHmu3yqlScwvX63CRdoI1SYaKK6ZILvrFshdLgxJpM5L/8x23so9kiawX1evLxPIYSDJasX412wQWjpbWYmr/tjUl7d88LjkNr/LxhmFiecwQ/u5rmuXcACXCZP+ArIcyNmzvxTtSXlsnlG+002ubZR0P+eS1Lapc2/oGpSVjRQH3x16XHPMkTG6DMU1WEUvJ626ZnwdTA4PSvjKa8mWUYX6Tx9vd3FLsKN0g+gfZSm/pmRNFXuW9HxqdBZ40AwAAAAAAkAMMmgEAAAAAAMgBBs0AAAAAAAD0Sk2zov/VNc1rZ0i9z//t956d/qB6pMhbHRjA22EHKwvvdA7hOOa+9SIvsWqNo1WMfjwqnj7SNsVIsh4v2cDaLtPsIoJmClN9mNT3lnvZFqyPV+ql9DDWQTdrrWriUr90xn0/sdOFG6S2qng16+yahkg9XNF6qcEz3axvdMfkdpIBxRqrRB7blj25Dt3w3b+LvLnNIxy12nFTNqk7D33STt9vcHjf3oQ7oVslcZmE+zlbm4VqZHkVbZLbiYcUbftged5VN0HNOckwuod74w5HfU8jvO80kTd1xhKx/Ml8tvtzKRZvhDvE7SG1LeCoNzZrZN/hiUpVc7JA6Te1fXgbuezj5bI/TCnPgtRw38SuV8q+OT/Tyd5F8VesMw0eIfWwKUXXujYmQ6TXB5fxegdM0rYq9etbks122q1pZwtdvO7qsLRLM4yavH5DTydRySHLif1LWcP7v9RYkVeihKYmqgKsGQ+nZBvs6212vF6r5eTT7FrVekEElGu7x5Dlq14j9bJX9c6G/InGZ42Dtd/FuunIITJUuHGv0WngSTMAAAAAAAA5wKAZAAAAAACA3ijPSEWcrW9ie8qoYqeWfppRLkC84+apg/X/k1GLknvwdlbfIaUFqflyarP8S57KKJnP1jBEzUEc8ah6spyC7K+4IfV5Y7mdNlOxLjNLdezRs8Vys2IfpJ9P1eqG6OflKZWvW/qLvKpbebqp8XRpPbZ5KmtlBt4urWXWXyPPfb8FfAzxflrkRg9PB4c2yenDYdexP1zkdF9W67x+Pv4dG+JS/nNx2UI7/cDkE+T+53JeT0aVyNiWid/i1ubHVeeiSNl23NO7nOUYKS8853Ix9AbZrk78v9Vi+fP+3G9FtkrtWjLMhegNyzL0Njmf+1YSjGbFjlO7UqV8Sh1qktPIqRKWZFS8Lm2qkjUyIiBoTdG6VMb+XJ+WL/bI6+xbLRxJ8KV/PiTyVsTlteDVZragC7pknjplv76pVOSVdJUL306mek9p96eew2mlPFbIJKXwKRF1axJSA/H+No4m+PkaKYfwrOG25G2W7dgjFSCGr1lpn7J4jWSAv1s3XsqnrjiYI0VuicljG1O4RSwP9XNdeC8koyB2JnjSDAAAAAAAQA4waAYAAAAAACAHGDQDAAAAAADQKzTNSphqC0Uz2XSa1MOePe5tsbw8zjqswf5tIu87VXN54SwlbRjGn5cebKebV0jdlbtQavM27cv3JutPqJCHGmdNT595sjjc52y20w0xtsNLxCOGwdGqdyq/qGTLPuIlxY5NtZ0h+vikvYzKyAIZIPVLg+2M3rvjPpG3PslWdgePuUrkrTxOrnvQgpPs9H/H/1PkhZQw2tdVjxd5H09kHXNY0/Xp9UQNLRvXYjY/38zaz40HynoyQFapHkusSLZP9XR6IrKtqC5HmhuRyLOWs0iTVQckzQ3JSEqZK/gWl4/bgxmXuv3Hj+b+zuIW5+14FB2zJqcUNnKeFlfW8lXXdWt2dHqZCpS8ssc+yrIiyETROtYq16VCjnpj3ZJsi6KPvadWvqNS7I446my/irC1q25b6m7lFwmIivtlvX7sjUPt9LLz5LkP7CbDWA/6PZebOWeBtmW+Du+iBS33lHD5uoqLRJ5ZKN9rSJXwcrJAvhPkbWQBdOW9i0TeKwa/EzR5vrwAHFD4lVhen2CL3ulVS0Xe3E58HownzQAAAAAAAOQAg2YAAAAAAABygEEzAAAAAAAAPUbTrOuW82Tfn7PfLnFokdTQqAzSDF2bTdb41SWlL+J1416209VjpE+zHkr5r1+zd3CTpn/2JPh37fv9+SLvlL5z7PStz06w0wlTMz7cwZj7c4jU2VEZXlf19dT9IXU/zgE+1lrND7Nvp87MU84Vy+4W3s7QIbJezPzNkWK52MX651OjM+SGFf/guulj5PcMNsl+t1bmHdJX6qdUbZ+u86tOcN2I7Cc9wo27jF6B7rErtMj66wjuLHltWNedcNa/ql7QwHDUMaskVqySyyv3s9P+Yc0yL8I6WI/uy5xy9nZV2yOhRPQ1IuVaqG61a9HKN7BOaihB2/BtqLXTpxRymnigviRj30Z4lOun7mWv05gKOoZZjiihlCNx2XlIJW3v5asHpsoPlOYx8B3ZVlyfSb/jWB/uHM9YLL2P1bJYHqkUeYsaWKe8vlGWRDQhO1XT5O24XFLP3r+Yr4PnD5b+789smWyn5/1AarM/q5dezOYGfucrFebrfGeDJ80AAAAAAADkAINmAAAAAAAAeow8Q7GRawtfN8kphq0lclphU4ItTso9cvq82N1ip4f7ZPjO6iRPTXk0K7WYNkV//fgX7XRkNzl1qEoYpgU3iLzvLDrbThcaK4yuwuareV51gKdB5K0y2FIvqkyzEf0VOYZuURROshSGSBy+l51uqZDbaenL93raLozmAXIKR3W982r2Zkk/TwdHy+TUcOSHPP08regdedxxLbxncGPGKUqi1MNzzOfsJkOOv2NIm56eii6P8IZNZxs51SpOm9nX7cvkF52zWskAwHZjuvmElxZxP0lsVWzKkgFZML5Gl2PbdWvllG2GP1tdKNiCMOnbQ2KlnDJ3DKOdxUZOJ6k9nwu5uHADqpbKknZwRairl7LIflmPvPcw6A1Zxzew45xRc4Jsj7fu/axY/snLZ9npx351nMiLlnI5NWiRqROqla4p80yvZh2qhLl3xeSxNqdYonrbv84Qef5G/l7tzzXZV5zHakSqjsd21xzGYyzi+cP24O9t3GR0JHjSDAAAAAAAQA4waAYAAAAAACAHGDQDAAAAAADQYzTN7aQi0JTV9szvYj3VhjiHZSS+btnVTn/VILXRR/Vf6GgzputaVa1Xla/WOQSzduz792cd82dG1yHxCZ+nW/odLfJOr2SbvNF+aWczxCO134/U726no1r46VmPPWCn46bUysUVO5uIkiaCLk075+bz69buEaOKdZ/PJctwRZzzHt62v8gbFKh1rFM+pT4R79SNtdMfvMY6K2KY8aHRG8gW8li3f1NDZ2fTO+dCrU6eqGyPLRXQvObErZ38lGyDoY1cGJ7xWrxzpZw8WvhrtWtM+WW5eCIux3DnXi1P1T/H+sr9F61P5hUqPJfNHjCM2pTUx2bTKfuMpGOefo1Ul/W+36N0AqlG2Adm4qBrZRjtpiRbvc6tGSLyHt5wgFg++9B37fR1pzlb8DalpGZ9W4qvbRHthZOkthxWfEaDmta9VPGLHOyV75gtjHF9u3b1iSLv6xqpaA9+wR3En1fIdQdu7LxrK540AwAAAAAAkAMMmgEAAAAAAOipEQFdHp7eMRNyStzTh+UDB5ctEHnVSWkXVpdke6Qyj4wq05jgx//bWng9YmyAbcbmhYeLvAq/nL5Xt7sqJqcYRgfYDuXWzYeLvCHBbXY6cfhBnE5EDOPt542dxeDf89RH/e9l3sMD2KqtZQ85TbTpQjnd89s92CZmYVOVyLt9K0s3vg5LaUyhR7Uran90RLfLdLRL2hpnq6NdQlJm8rdl+4rlyhNkVERJU6+TYxDeAf0dZRYiep9uXdTO23hV1kGkvLwTn2Y1qFonuQulpVWqWdocgcyUrFLai9KOiJSfCyMmXaKMwrVcwG4lGioR7Su346/jfE31ZChdgLC/s7a7cwOm9ijibbB6VSUZepS/lBayM6rIEtV+2NqO0gl4mvFcLxNPvy4lg5MP4Ci1V496XeT99JPviOXlr460049V8LiCKFznduy3VRVNskCzmMsSZdWltXNvi3NbjStqjcgQKZ1advSDYvm8qkP4dwxjyQkxfe737bTn7XlGR4IaCQAAAAAAQA4waAYAAAAAACAHGDQDAAAAAADQYzTNmrbK5fU6aprXnr+bnT4sJMMrfhgZJJYrvI2OtjgDAxz2ubh/xFEL3dcrbe0akwWOYUHV/RF7+Tk891VvcOhoa5+7b7XTJT4ldHQXvtdJbNpsp31KmhjUsqdYDj4cd9S8lXrDGctBD7uql5mOal/k1gS06nf7+WS5NCQKHMss+knfrPsEhmGGW5zDWOcrk8y1nqt9tnb+BiWUMzTM7cLXrNo+ZrHw07TmajkpLlkZdemBWq4AkX5yH8orB61IBmAp2FH4tHeJsqHqmIO6WFUrW/UdkpRWf1Qb1lQFLAEzUbBrnViujfB45L2GMSKvcI4cj7Tsw33eMaOl5VxKaaDZ3heKa9dd9XuEW73uapp19fqdSMnvzdvG70E1PCPfc7ppCr/nRHyydpidnrDpTJE3ZN4yO+1sQNk+uu7oCwAAAAAAgC4CBs0AAAAAAAD0FHmGHskpFZFyCZV+C3hKpyYpIwqVuaWtnF+ZJoppUw7T+q6009Wa5GJeywg7XeyRUZMq3HI6f4iPZRYLItKGbVbzLnb6/GPfEHlPPngEH+erbFfmViLZ7XS06Tt3IOBcRprEZkWMreT8ypSNPv2jR5dykl9Y67bXs0wj29SUphZxlA0RZlKZHGqDfVN3x1R+aw4FTafgUvavywBAHmgRAHXccW53W7ZKG093jNugv865PQbkDLMRj8u+RFFIGQVbnKM6epv0CqZpAUC78WiyOZmXcuyL9ciozUbAcfo+pPoHUjS5FK87erC0+wTfcNAgjhZMFCjn8KjSL0TeR5umiuWGFh4TtSTluGp9uNROe92yfKMJvrb5PLJ/0GUWpiK5cWnyjH5BloeEE3J8Nr6MLXjnhKU8Y0RA1oVxA3jdUUUscyW+HM7RnI0vGoyOBE+aAQAAAAAAyAEGzQAAAAAAAOQAg2YAAAAAAAB2iKZZD3HtZZ2Ky6ONy92KdVokmreOzoznbz1z91/+bKfXJmQc103xMscQ10lNv/VxS6mjhU6Fl3UyDSmpd9ZpTAUdrVrU7f68/GuR9+/66UaXR9PppqK6vxjj+5I14sSyMIdaLvDI81ubcPaUUu3pdBu5bEpMXf+sloW+vyKv8+/wN2TRJivh3S00O8Tegq7tFnlKMbRFgq5bkuX7XdOt9U9qJXHrsWI72qCom5LjvETLuHzLSmtF3rYw50X7yn5bbVWuGu09lZCmkS3h76ZiWYTxWhjtxqHc3xZux3UEkPbYWdOs2sZZ62bRkuv657jhcXx/JJLi8cOM/tIS7TVD6ud7K163PPfbYoUZLfsIf4Nc11fA5zuhdaJ+Zbt+j7x2qddar7b/hMvjqFlPaGMen/LdIp+sF2pdCFVnv3aOLd7srIsfyvUkKCXe2w2eNAMAAAAAAJADDJoBAAAAAADIAQbNAAAAAAAAdJamOVsYa1U31lGWwi0nSK/BtSeyLub/9vxE5G1KFNvp+eHhIq9U81QuVEJc61qgDbE+jppmNXR2paJvzuQVvD7O29FRNdXrElo47uPZ77nsMaNb4FI0vXq9SDbI39eg6IjLfLJcwop/pK5XUrVVevhtXbesrqtr8JIuLqfaBIchJQb66x21eq5k7/Fbbi+uQuV8aqdLte3UIzCrRaRrltvi92wqWkzVs1nfqbuA9a8Ewmrnp+0ObeJ+c/PicpFXsp7PbyIk+1SvYt3eUinLxa3plv1rQo6h2OPcxRsFm+R2wlVon9uDa/J4O13q/szxPRDdW98p/kGmftlj8rJH6yBUn+a9Q9KP+DVjUh6/oOfTSk+udKpxUw7rAjUyXkKwgMstnpJtTtUq6+HNVVJann4dVrvuFs2LOe7zOL7LpHpDB9fJeBc1Calnj6a8GUNzE7ESPgLZw28/eNIMAAAAAABADjBoBgAAAAAAoLPkGfrUu+MOBg4Qy/ERbDO2bTc5JR4eIB/xT5q52E6f2/8RkVedLHEM2bk2ztOFe4ZWibz/1Y8TyzXeIkfpxrRCtoCrS8ljrfKyzdLPl50q8vqH5LTCX4fNstNxZVqKWBrnqah6barkR+PestP/MSqM7oCZMvOe8o0p0yspbS5enf7Rp6JU4oo9USYZjZMNjr5dfbpJTENq+9etz7QDz5LZi1CtqrRZPnGqs50u59nBNqFKNVrtQrcIBHmx/mDuD4tkF2uUruI26G2RbcdbxzqLRJkMrRzpK9uyr1mZwo/K7TQNknZ1KrWV/D3vsCEiL7F6rbO1HuwGLbZN4Gvrq2FZRk1JnuwudsvrpUrQFc/bjk7v37cpsr39A1oo55lT7HRg1hzHbfY2VHlCTNOxedfI8NPFQWc7VyfJh25PF9Qs57ya2asqs9ClOTFlnKPLKlRcmiWxfv1W96FKNYiUp4MuHhnAk2YAAAAAAABygEEzAAAAAAAAOcCgGQAAAAAAgM7SNEePZm1R5bXSFmZSyTo7Pa7gfccQmbr+dFHLILEcTrFu7euY1EbXKxZhumZmS4z9iG5fKUNRvzn1AbH8qw1H2Wl3gdTwbE2y3vmUImkrZxj8Oy4a+q7IGemXGqKXmgfa6Q2a/Vx/H1ubDfdVi7yTi7/qdprmtnBIn6V2elG4SuSpWifdwk/VwOll3150XV2jot3TtVRtsT7rtXg74CTpemdX/rpl1WbO1PRtovz8Ukfbq8mi7/XsuotYbhnLNlbJVVL3GivjcxrtK+tB8QpuV1rkeqN5mBbut54vT/Fi/fmOsxje08TrrjhPapqH/lbTNEPH3IqaQ9jiM6k1Otn3yjJIqlaOmoY5leX5nB5GW7Uv+3tjpcjbdiHblg7kV4V6Hdns4HQLv8QmDjdNBL1DHbeTUPTG+nUvmuT26NXydMu5VNK5vCNJn+N21HDrZqE0i/sqLMeAZV6269VRLt8dDp40AwAAAAAAkAMMmgEAAAAAAOhIeQZFAXS5vvnKPr9nu5fDixeK9cJmIKMcI5M8QaVUe9wejfPhbYnLaDAqYwKbxPJJJRzF6N0/7yPyDohcLpaXH8ZWdm+2yKnEaiUCzRkrDxN589bwtN++w1eKvAnF6x2lJMUeGZ1HtctrViIhER9HWB7SbdAs9bKhR2BUKfW2ONYhVZLh1qK9qREA9WmjVpGnlHn6Iq+0t6mNhxzt8JK+bDqBjpGLdHvUiHzJ/CMC6lEAZWaW3Wn1wHRnKSM1q1zrj2q2Gr2WLFKFtcfLafKCJZxOBuW59ytKtvBQ2R6K1/PytrHa5UdrOiElsmDd7nIfwS383Whfedz+Oq5ELVXS0sq1J0e7I8z58toFDOM7E+fa6cZkgaOUQp1KJ5KGJy/rTx2/ZhnbT4m2u02RSBI/3+11O/2YIaU3ID9K/S0ZbeR0SYZq6ZZLCplqFdrVcJRXppRrZFNCjnl8ipVdslDaSr69WkrEzhzzqZ2uT8h6mkW9st3gSTMAAAAAAAA5wKAZAAAAAACAHGDQDAAAAAAAQEdqmjdePNnwBL7x8vht6Z/sz/+xbV+x3pDgNjs9zF8j8iYWrHbcfrFb6n13LWGt00vNg0Xe23Vj7fRAX53Iey88yk4/9dvbRN65V/1ELO8364d2umG4vIdIFLKOrmSi1Dr+as+XHcMs1yVlyO2+gWY7XeZxtklRteB6mFLV8slMRg2DI3x3W2rixY7hNFW7wYCmeVNDXOtWN7qWrl7R5On2SSFP1FG3vCnlrKGPlXWiYKqHYAZ8jjrlrHqzfENstwFX0nQ8gFRItjmQmebxUvNfuDDgqB9PqqfUr+sg3XlbN7qUkPSulNyHWzmcgkGsgSUSjdx2vQ1yJ427SI1s0fzsx9AbOaWM31daEBniaDmXzPLMTQ+jretas6Hqpss9smwPLthop58I7SryUmHna2tPY22LfBdjQLAh43tSmSgP8Hlq1DTF6nUwkeX1nJR2LdVDbqvvFqk65W/2wd9tSfgcv6f3K9F1su2GxrI1Yq0Z2mG2sHjSDAAAAAAAQA4waAYAAAAAAKAj5RmhLSnD8+1020sNk+zPRxZUO067v9Y0QeQNLqi106Uelh8Qu2jWcZ9Fyuz0q9XSKqiqgKcjNsdLRd7WOIeaCms2bv/vzjvE8u2bOWLgSX3nibyJfpZk1KXk/cUiJUJhYyqY1UqtXpFrFGu/OW5yEXg0u7IyN0+jNEwot9OJeKRHyDNUmUU2dKubVJbv6ZH9dAs6uR23Y/QjNU+3AkxkiTZkKlPKvRnTp5SRbiunFl8nnS53wnnDQsGDxwYZce/O8jfCs8nvKMHwsfrMIqVeVRJaxLEC5xPu0tZVm6TZSubBlSjSIo8tVcHT04FN8hIXrpB9Rzc09exwvAP6i+XJfj5HH4ZlZ9dXkUuoEQD1CIG63E2/Jqr9tB49sMzDFeqaT08Wec9Nu99OtxwixwSBWSwr6Ym4g0FHizf1fC6Lysh5OoWKvWpzQrYdFb0MQ16WQ8REI28tz1AJeqRUR/1uUhtXqbIP0yfzCtfI5SLFvjeq2dKmstnCbie4ZAAAAAAAAJADDJoBAAAAAADIAQbNAAAAAAAAdKSmuWh91PB6Xa00Nf+rkfq3/sFGOz2peK3IWxpmvc2CliqRN887VCwXKFqYUn/EUZfTz8f7I0YEtjjawc2JyH1cXPG2nV6TkDYuLzaPsdOLwvJY+yghvxc0yLywphOKJvk0RxJS410a4N81pa+041tqDLTT1RP5/iYVcRvGc0a3R+iPs0iQ2mJXpNvtZAv9qW5X10Kr9VvXxSdC0C23xXKudSYn9eJpQ1HnjS63UzXNiWJZtp3oVNStaB5VkvUcKq9iGElNFiks5zSrOE0KKfPKZNt1q3ZUXi1MulJQ3tVSd2uO5L7ZrJY7jMnXXwzvQL4eJTbKd2p6C/X7DxfLHhc3wrAoTMOo8DY6aprVvrdCe3dHt1qVtqGy0av97QEjl4u8kNJPbx0n+5iqWUaPxjRVzbjLcaz07tbR2jc3iyXV3lW3jtPDaqu4lXXdWSzm9O0klPGPHp5b/x0RRZscK5Xf67tUaqMLFd9J/XcgjDYAAAAAAAA7EQyaAQAAAAAAyAEGzQAAAAAAAHSkptn9/heG2/WN5uTp1/e3P//1CU+L9d5RQly/tElqeBtirFeqCEmDzxJNm9xXMQAtVTTERFDRT9Um2JeZiLp9jqGTN0WlqO2DFOt/4impaIwqy6pmiNgW62enqwrqRV6jZuS7qrGvna6pl86gkRAXwftJDv9NHDVgIe9/C/+OZLQLh3FWdFdtQQ9/nQ1Vi5zNh1kPyaqj6qB0n2avEvozogo4OzlEZ08hGVBOkq4pVqWruodzB+1fleZpcnXDHee91I2Wms1yfsWhV5P69t0VJ42gKllVItV/812fEv465uy9rBe2v5B9YFtpmmPy+U5LFVei8nmyQZbvy/76yzbLg9O6eCNVqbzH0ks1zeuPlg1kbpTLoUnTNKta5JjWLw731jg+jSt2S41zpYev9V/FpE90Y4rLbL9SqWkOK/tvGifrS29C91BW38lZsrlS5A3TNM3qurqmWPVi9mrXxICH25w+VtJRr6f6scaU72bzd46Uau36szrtdyScxwHQNAMAAAAAALDzwKAZAAAAAACAjpRnqIz8+Ud2+r4vTpV5lyy100cP+FLkzWtgy7c1imyB+FyzoPMp1iQhX8wxNKPf4xw6WbciKfTEHK3r+gakXKRYCdOoT9+reLSpgU/qpYVP/xBPRe1SwlNYujWLPhX18MppvI0/fah8J24sMrooLlfeUo0GRcYS8uc/1aZOEeqyjmzhWrOF7dankNSQsHqIzqy2aFoo9N5K05BgftIJfVZNDZ2sF1eW6mS6dRmA6SgtUOUhoRpNuwEsWsq18LZ+efILqjldO07mpYK87G2U21Ht6YRMhyR4RXIKP+ln2Z2bbDYVhoxjKYU5S05Hb2wsVo5btkezLOkc7r2XMnL4Frns5YI5qJiv5fqU+Octw0TeQUqT3+fnV4u8ssd5vED8fe0HdrrKu0rkrYhLu0OVwcqIZcqYlSJPiiR7Nvq4Rlzn1km5qk5dPGSnl21jmSnR2MTSmFTSWeNgJrWLoFv2AS61Y3c5DxF8ftkJlPlZhhsv0r64bI3juCuuXZSzWVtuL3jSDAAAAAAAQA4waAYAAAAAACAHGDQDAAAAAACQg7YpP9wew3B9qwFLsYam9O8fi9W2/p3Tz5wyQ+Tt88s5dvrY4Z+LvLF+zRrFYD1aUNMUFyoaxoimnVXvBN5vGSLyktp9wv9qd7PTdXFpT7Q5zNoqn6abVtFtW1pUqyTSWrWw2MujaX8ib7OmaOUiGY68dBafq56OTxM4qjpi3U5G1W/p4a91fblqOajnOa2XaZ8qsJzLjTeivFegRdRW5W6tnItczlZx2c67R7GR07erv46gauW8q6BpzkSkny4E1zTNW/m81ZRobUUJee3dJAstqWijA7Xye41hqYMP5flIx98o32toqmPNpksL422G5fE0D2H9Z+hTo1ey5fXBYnnbaG4wbuUarNt99vc5q4j9Tdnf7Qgr1+y6LAJU/R2VmiTXuzlLRoi8MQZbDfZEXIoYONv1ydeU3W+tzMe64ZBftp1YkMticJm0eIsq4bBjSdmOsu1Rt5XzKO+q1TRJ/fXAYIOdnj1A69Ob5TtnZZ5mR0tg/ZrTkeBJMwAAAAAAADnAoBkAAAAAAIAOlWeQJMPVtnF24bOzxfKXzyppQ06vuKYcL5ZbBrBcIrCVreGIxmGcV7JcPrZ3R3mqP/X54hxH2JQlj6cK8o9XZxiKq5JFRda1vzJ6FG2ICDi3hqUzQwZvE3lhxZtKt4pTl4s8sl5kW1edWiSiyrRgyOM8969/z/Rk8z7rqJh23ZviN7nd1Y7ZXeRFyxR5hHQZE7S2itNsjfI81eEBzlHpgp9JuyuINb4hUahNqbbIcxjpo7YXKa3yBJVIXXG/Y6TBiHS7MiJbpTzOX6jssx/bfxLj+rDl3CejB4o8MxV3tsLS5BqxYm7bLOroXVTdynamxKgrOWqt26gVeXOig/Ky8FQtHzMxJ1LlKMtsSLFMZ5RPSi5G+fjYdruDr8+9ou36WHPQnJDtKpzyO/abOv989QA7nSiRZy1Qw2W60iOt/3S5nIpeFcQx6JZzSv/rSsjMpxv2stOD52Yv0eYUR6uMaRKfrLaw2wmeNAMAAAAAAJADDJoBAAAAAADIAQbNAAAAAAAA5KATgw22HXPOArHsHIjXMEqkDEuAQMbdgyHFbGkzxCc1zSE3h9WeUrBC5PmVEvZpfmKl7vyVbWFFeBXUBLIvNrEV4SCf1PWFRkgtXStbRhXFmrE3kWzgczTkz9Jasu6ECXa6pZ+8b48XOuvS3NnCumrrqvq7klWyjvR9YVHG4wSMOTIsl1dLxW8imJ/FVFLKlA2PIk2u+kC+j7Diu7J8VZlin7flDl93sz1nqVb2oVIWyreEWQNLFK6W7bP8Rdbe986W2pojv3OunX796Ue13PV2apuio/0GXg5XyvOsVQPjwIKNdrrSI23HQi4O6z1C0TAT0676oZ0uXiStbns67iI+Tx7tuifCaJdmHwGNvEaGNO+upJRnvroFX7y0894twpNmAAAAAAAAcoBBMwAAAAAAAN1JngF6AErUolz2a7O/HGWnPwlI+0Gjnu11TF8q79s+T5Pb2ftGk2Codje6fZlbca2KaVM9FZ9m8fTppXKMbPVAj+RU8g+eVpWmRobhHTjATieGVYq8aJ+A3IVSLAVrpczCXLXOcf9Jp/pqfRGWgcTIs6VVpxlnuZQuQ6rQ6rx7IkubzEVyO65dR9rp1JdLRN6YN/M/vvK/Zsl8MP/toLW2xvXBZ3Z6RtUkkRc5bqqd3jpODh8KDqyx0/3fZPlFa1NCw9hn1pV2urBCSoGKni12jDZcbPQuSYZKYiPbLH61fIrIW7aR+8qKOTmehep9Xjft/3782v/Z6T7DpISy32eQZwAAAAAAALDTwKAZAAAAAACAjpBnmN8+sk9QXLzu8/S+x2KVg1Iu20vHlm/+8oxUC79K70ppEowWnjg1E/nLM1yRjpFnmIo8I+WXmcmYnN5KqCv36LLtnHogSLEMIJGQUeASceeIgImkdGIwTd5OKmv57Fh5RncpX5cWVszUz6GptElTk2coZaF/z6XkZS+X7kd3KdvtIRHnNpmMyuFDMsxlm1DasbWslbXa96vfs5Zjvk7pW3tS+arnj3ApApikpqRqfQ57hjwjla0OKfU03zqUb/m6zDxqwLp164whQzjkMegarF271hg8ePB2bwfl2/VA2fZsUL49F5Rtzwbl27vLN69BcyqVMjZs2GAUFxcbrmwicrBDoCJrbGw0qqqqDLd7+xU2KN+uA8q2Z4Py7bmgbHs2KN+eTb7lm9egGQAAAAAAgN4MXgQEAAAAAAAgBxg0AwAAAAAAkAMMmjWGDx9uHHvssTv7MIBhGI8++qil9Vq1apX92SGHHGL9AZAJqitUZ6jutJW3337b+i79B10PlG337L8//fTTnOuiX+9a4xsqt9/+9rcdtl+Xy2VcdtllRk8Ag2YAAACgl/Phhx9aA6W6ujqjK7No0SLrONWHKQBkgl60pLry2Wcc5XJ7waAZAAAA6OXQoPn666/fKYPm119/3frLd9BMx4lBM8hn0Ex1BYPmbkxzc/POPgTQSZCFUCQiTecBAABkx+/3W3/ZoL6V+lgAdiY7ZdBMXnhXXnmlpa8JBAJGZWWlccQRRxjz5s2z8knbtPvuu1t3lIceeqgRCoWMQYMGGbfeemurbUWjUeO6664zdtllF2tbZBb+s5/9zPpc5ZFHHjEOO+wwa1+03rhx44z7778/r+P929/+Zni9XuPqq6+2P5s9e7Zx1FFHGaWlpdbxHXzwwcYHH3wgvkfTAqTlod9x5plnGn369DEOOOAAo6eS/r1LliwxTjvtNKOkpMQoLy83rrjiCnswmU2X2F4d1ZYtW4zzzz/f6N+/vxEMBo2JEydaZZYmHo8bffv2Nc4777xW321oaLC+89Of/rTNdSqt0/r73/9ujB8/3lr31VdfNXojudr0e++9Z3znO98xhg4dap/Tq666ymhpaRHbOffcc42ioiJj/fr1xoknnmilKyoqrPJJJmXkOXoiRutTGywrKzPOOeccx6dkVCdPPfVUqx5Qee+9997GCy+80IlnpOeAsu35UL+bvr6NGDHC6tv090l0nnrqKWPy5MmWzzD19RMmTDDuvvvuVutRv/njH//YKuvCwkLjpJNOMqqrq7NqmtMadNrHr371K+v6T9fZe+65x6prBI0N0sfZE7Xqq1evNi655BJj1113NQoKCqxrKf12vUzS2nEaf+Q6z/mObzJB7fb73/++dZ2ldk7XvIcffrhNv4mulfR7qJ1S3Xn33XdbrTN//nzj6KOPtuoU9RGHH3648fHHH7dab8WKFdb5oHZPdWPfffc1Xn75ZTuf6sSUKVOsNF3703WlPe9EtDmMdkfzwx/+0HjmmWesAQcNXrdu3Wq8//77xuLFi4299trLWqe2ttYalJ588snWAIzW//nPf241TDqhBN11Hn/88dZ3L7zwQmO33XYzFixYYNx5553GV199ZTz33HP2PmmATIVM61MFefHFF60KSdu49NJLHY/1wQcftI73l7/8pXHTTTdZn/3vf/+zjoEKnQZXZISdHpTTBWTq1KliG1Swo0ePNn7/+993WAjOrgyVF11gb775ZquyU0dH5fnYY491+L7owkyd7bJly6z6RB3+008/bV1w6SJLA3afz2d1IP/+97+Nv/zlL+KJBtUR6tTPOOOMNtepdF3417/+Ze27X79+1u/ujeRq01Qm4XDYuPjii63O/5NPPjH+9Kc/WVGxKE+FBlAzZsww9tlnH+OPf/yj8cYbbxi33367MWrUKOv7BLWjE044wdoH7ZvK6T//+Y81uNJZuHChsf/++1sX3muuuca6oFCZ0cDt2WefteoGcAZl2/Oh6yz1b08++aTV11FfRtAALBP//e9/je9+97vWgOaWW26xPqP6QAM36nNVLr/8cuuBEV0racB31113WXXpn//8Z87juvHGG63+mm6sqJ8+8sgjjR/96EfWNYWuyVQ3iPT/nsScOXMsyQxdmyhCHZ07GsfQ9Y4exNFAcXvPc6bxTSY2b95sDUpd3z4oonrxyiuvWA+r6MET3VTn4p133rGOhcqPBt333XefNcaj/oIekqbb84EHHmgNmOlBFV276ZpNv5m+T/1G+nimTZtm9Tu0Pep3aPBP127qq6jdU5244YYbjN/85jfWtZy2S9D3tgtzJ1BaWmpeeumljvkHH3wwjSzNxx57zP4sGo2aAwYMME855RT7s8cff9x0u93me++9J77/wAMPWN//4IMP7M/C4XCr/cyYMcMcOXKk+GzYsGHmMcccY6Xvvvtu0+VymTfeeKOdn0qlzNGjR1vfpbS6/REjRphHHHGE/dl1111nHcd3v/tdszeQ/r3HH3+8+PySSy6xPv/888/NlStXWulHHnmk1ffpc9pGGlqHPqPvqHWD/tLcdddd1jpPPPGE/VksFjP3228/s6ioyGxoaLA+e+2116z1XnzxRbHPmTNnijrQljpFy7TuwoULzd5Orjadqf3dfPPNVvtavXq1/dk555xjndcbbrhBrLvnnnuakydPtpefe+45a71bb73V/iyRSJgHHnhgq/p1+OGHmxMmTDAjkYj9GbXdadOmWW05zVtvvWV9l/4DBmXbO7jtttta9bdOXHHFFWZJSYlVLk6k++/p06eLa+VVV11lejwes66uzrFfT5cX9c16/Xr66ad7RVlmalcfffRRq7FRW85zrvGN07X4/PPPNwcOHGjW1NSI9c444wyrf8h0rPr26O/TTz+1P6O+IRgMmieddJL92Yknnmj6/X5z+fLl9mcbNmwwi4uLzYMOOsj+7Morr7S2p16nGxsbrTHY8OHDzWQyaX02Z84cx/FGe9kp8gyabiN5A4m0naDH8meddZa9THeb9ASXHsmnoacYdDcxduxYo6amxv6jJ77EW2+9Za9L0xtp6uvrrfVIUkHbo2UdkoLQHTPdRdP0UBoSlH/99deW3IKeuKT3SVpluuum6QZdd0V3cr0J/ck93QETs2bN6vB90TYHDBhgPfVIQ3endPfZ1NRk3Z0SVCfo6Yl6101Pv+mJyemnn96uOkVQHaKnb72dXG1abX/UVuic0h0/9ac0Haejtxl6SqC2fSp3mjFKP50kPB6PXdfSbNu2zZoNoNkPkhmky5PaLj3xpLZM047AGZQtyFQnqKyp/8wFPeVTw0RTedOMA8kPckGzC2r96k2ov5skhlSvSTJI5z4tjWrveXYa32SC2jHN2hx33HFWWr0uUjuj8VOm49HZb7/9rNn5NCTnohml1157zTpO+qOXQWmWaOTIkfZ6AwcOtMZbNPNET7XTfQSNB1W5K40Z6RzQU3Z6Et9Z7BR5BhUYNQbSvtFJnDlzpnH22WeLE0XTEXo8dpp6+OKLL+xl6hRpSshpCom0rmlo2oimLT766CPrkb4KFTpp59LQQIu0MSQH0XU+tE8i01Shuj061jQkGehNkBRFhaZeScLSGW87U4dA+9Njxaen69IdBl2ETznlFOMf//iHNc1H00Mk16DOSB00t6VO9caybW+bXrNmjTVNRlpTullR0W9aSe+mn39qT+r3qFypM6WOUoX0ciok26GO/te//rX151SmNL0PMoOy7b3QjUksFhMDObpWkrSRZDAkU6TzS7IJunmh6XYdGhyppK+Nel3JRG/uX0l6SBJHkn7SzZ8q7cz0oC/f85xtfJMJ0kWT1JGkHA8++GBe18V8xgXEmDFjrPFYWntNab2dp6/n9DBy7dq1lsyW+oi0VENfj6D8tOSjRwyaqXHRXRDp1OjO4rbbbrPueGgQk9Yr05OFTKgVh04iaZzvuOOOjOtSJ08sX77cegpMTw9pXfqcnlzT3Qrpt/Qnw1QoVEkef/xx46KLLhINN70uHfOkSZMy7lfv7HvrnXIa9eZHvxFKo78I1BmQNoz0UaTFortZ6vSpTtCLg22tU2l6e9nm06bpgkovjtEFmDpqOuekPaULAWnP9fbn1PbbQ3rbpImkpyKZoKc3wBmUbe/WOqdn6wi6eaIXqehlUJp1paeE1J/SHw3u6GZKfQk732u5E725f6WZFTqnpBemp7R0s0LXT7qOZXIRyfc8ZxvfZCK9L5r5P8fhYeEee+xh9BZ2yqCZoCcJdLdKf3SXQi+U/O53v7MHzflATzA///xza0DsNBgj6KU/erpIT0LUuzF9qj0NTeOTmJwe/dO2aVqgqqrK3idBQvXp06e34Rf3HuhprdoQ6YkQNTx6SS5996u/CZ/PVF0mhg0bZs0+0PbVp830Rn06P81BBx1k1TuSaFDZ0tTutdde2646BfJv0/Q5vWREF1O6qKbJZ2rXCSrXN99805LgqDepS5cuFeuln4aSZAfttf2gbHs+mfo7eklTfVKZvg4S9OCJpuzpj/pfqhv0UIKe+nfmzUpv6ZdpDEKDVCqDNORCtb0+2tnGN5mgmSFySKEHW9O3o52lZ+lVqO+gFxrTs0+U1tt5+npO1/f0QyvqI5zWS+d3Vl3Z4ZpmOvH61ALdtVKh6ZZe+TwBoScaDz30UMapjbQncvoOTJ/eoLs4J0geQm9203boSQrpiQianqSBFb35TZ26Tj4WLz2de++9VyzTm/RE2kaGGq1uNUNv0rYHmiretGmT0ConEglrn3TBJc1xGmp0ZE1FN1F0l03rqdKMttQpkH+bztT+KJ3Jnqot5U7lp9pG0nGk65p6HPTmNV3MN27c2Go7aK/ZQdn2HmiGgFAHZXS9o4FS+i/9/kb6eqj2remnjW29jnfEcfZEqG3pT4mpDXTErKzT+MbpOEjaSLrmL7/8st3tjKSxqvaZpBbPP/+8NVtF+6A/StNnqpSTnDJIVkmDfBo/pPsIct2gbaahazPJR+jhXLqedkZd2eFPmumFDSowGrzQtDgNbKjwyF5FvaPKh+9973vWFDu9WEJPjcl6iCoU3W3Q5zR1RJ6dVBDpu2KajqDBLg2KqNPN1Nmmobtlmo6kjpmm/+jJJBXaX//6V2sASNMc5P9Hmi4aaNExUD4NynozK1eutKxfSN9GlfqJJ56whPxpGcQPfvAD4w9/+IP1n8qHBtB0x9keSPhPF02aCp47d67VYOgumjTsZLlDd8gqNEimjof07STD0K2K8q1TIP82TVP2dKNJ0+jUTqiNUAecj6bRCWrLVDZkM0YdLHWSJBfIpPWjmzjqcKm8L7jgAusJJXXEVDfJFo1mFkBmULa9h/RLWjT7RhIAeoJPZZEeeKhQ302SHHpBmuoHzRRSv0qSxc62f6N90ACLJEJUJ+j9lHQMhp7Escceaz3cIVkGtQGq09T2yF6tI3Aa32SCrtd0Pdxnn32sdkbHQ+VPg2A6JkrngjTGtB/Vco6giH1pyPaOZqmoTdPMBb2LRNd3uhFT43RQ30D2iDQOo+2RVzPNdtHYg/qf9Kwz9U304uQDDzxgjQWoLtNv2C6tvLmDIeu4q6++2pw4caJlI1JYWGil77vvPnsdsp4ZP358q++SZRFZpqiQvdgtt9xirR8IBMw+ffpY9kXXX3+9WV9fb6/3wgsvmHvssYdlcUKWJPSdhx9+uJXFjmrJkmb27Nm25UnaWmX+/PnmySefbJaXl1v7pe+ddtpp5ptvvtnKgq26utrsDaR/76JFi8xTTz3VOmdUHpdddpnZ0tJir0fnkCxsyKqG1qHztmXLlnZZzhGbN282zzvvPLNfv36WXQ1ZUDlZzJAlz5AhQ6zt3nTTTRnXybdO0TayWXH1FvJp01QnyBKJbACpnC644ALLglC3A6I2Tt93qlsqW7duNb/3ve9Z1ldUlyhN7TKTxRBZGJ199tmWbaXP5zMHDRpkHnvsseYzzzxjrwNbstagbHsXZD9G54+sNLPZz9G5PfLII83Kykqrzx06dKh50UUXmRs3bmzVf5Ptl0qmsnCynCN7uUw89NBDlh0dWar11HKtra21r2vUtsjmdsmSJdZYg9pSe85zvuMb/Vqcvs5eeuml1vWT2hm1N7J8fPDBB3P+lvS1kqxhyQqSrqtkNZmp3ObNm2f9VvrNoVDIPPTQQ80PP/yw1XrU7mmcUVZWZo3rpk6dar700kut1nv++efNcePGmV6vt0Ps51zf/iAAOiSqFN010nRN2hwfAAAAAKAnsFN8mgEAAAAAAOhOYNAMAAAAAABADjBoBgAAAAAAIAfQNAMAAAAAAJADPGkGAAAAAACgI3yaKdrPhg0bLJ+73hKNpytDkwPkn0oBBtQoeO0F5dt1QNn2bFC+PReUbc8G5duzybd88xo0U8GmwxeCrgNF1CFj+e0F5dv1QNn2bFC+PReUbc8G5du7yzevQXM6qtoBxkzDa/g67uhAu0gYceN9Y1araHftpUPLN9sdczvl8y3HfhOpKk3REo4+lFy2Mu/tuMeNEcvV+5TZ6fJHPjG6Al26bMF2g/LtuXTXsvWUyShwS28aZaeP20NGVHzjhSl2etAfZxudzdbzporlIaevsNNL3xkl827u3OPpruW7I3DtJaNArjmS61RAi2DtifI4oPLdLSIvuXxVBx2Qq83jjnzLN69Bc3rqgArW6+rehdsj+LYOdNSUToeWb9Zjat+g2esLymVPQNld/sfrVr5HePy83S5Tr7ty2YLtB+Xbc+mmZetx+cWyu4D7xUCR3K8nsGP7TLWPJnyFfKyeoHZd6Ozj6abluyNweWRZqGWjXXYNjzKIVa/l1nY66jyIMjI7tHzxIiAAAAAAAAA5yOtJMwB541Luw1LJrKt6xvD02lcXVYi81079o50e5fusgw5Obidqxu10+NecJqb99ad2euj1H+a/C7dHLuc4BwAAsCNZ/o9JYvmqSW+K5VNcS+30xw1SAvH3C+600598b4TIe2MrT9HPXTlU5KUa5RNEb1nMTl+8x7sir9QTttOjA/eLvDcbx9vpY05fIPL+e8Q4sVx/cSXv/4slIg/kgf7ENYvMod8968TyXwe/ZKcL1TGBYRh9PCFe+K3czph3z7bTJ+36hcgb6Jc6jz/NP5S/d/EykZdqbOSf4ZXDXDORMLYHPGkGAAAAAAAgBxg0AwAAAAAAkAPIM8D20QY5wrTPeUqOOL/P3+x0X7d8GWWjspm3W+S9XYWn2U4viFaJvMURuXxo0WI7XeXlKRtiQ4Lfku3vkfKMuRfcZae/OEf+xosX/J9YrjxhifPvV88PpBptmhJ0eeR5N5Pa+cv2VnQnuLhEZ7JzABGYNYd3t/fuchdzF273/no8uV6o2gHnbdNzLCmouLtA5Hnemmen3SFlSpmacpglBN2B5lP2sdN7DGYHCuL/LZsmliuLmuy02yXL4I8bZ9jpvUrWiLyTK/h8VQZ4G8SshbJ9HD2G20djUr5E9lkj2309sPUgkbdrX3ZbeGPjriJvSLGcvm/5Y8ROB44UWSAfNFmFYTpfv/YplS5WX8bK7XSZW7aVuii//DfOv1Xkvb8/y3EqPYUirynF5UlceRg7bYz80/kib/S5c/lnFMh2bSrSjfaAJ80AAAAAAADkAINmAAAAAAAAcoBBMwAAAAAAADmAphlsnxYxi053t7myel1dLqPuvR/pY6fLFJsha7Mm65DK3C0iL2Ky1vXggrUib3pIWt9sSPK6dSmpm+7vYd3d5mSRyNus/Kxit9RSzZ/ylFg+9L8n2Gn/EatFnjg/bbDwARloy/lq57kNn8TaT2Lr7lx/IqOiIu/g37Am3m3ISFYbDivotvrXDo24la3O69/T181zH66ADJBgRrmczP2lvdrpf31VLJ9fyjaUh/6S2zHheUtZSKWM7sz6w/n8bV43SOT5A/J9jkiC7eGCXpm3rK4fr5eU/buqf/a75XVh6miped0WY73qpoiMSLipmZf3qpT9e3WE+2mPprf+cvNAsdyviN99iR6jvY/wMr+PADLT6p0S5Vrm1gLLnFSsvMNhGMa6BPd/QZe0eNtd0TGvTsh3BT6LDLPTZxaz9SFRp7VBt8HvSO36Ry5rQqypvwuzneBJMwAAAAAAADnAoBkAAAAAAIAcQJ4B2k6WqdJt39/PTt8+4F6R92qLnIbzGTxtUuyS04Bxxe4mZcpp26TByyu06R2PFmfe50o65kUVmYcq1bD2r9xPhlMymtULzXKf/xz7Dzt9wpk/EXkl//iYF3qrHKMtshQlry2RmzZdIW2zBr5fb6fXH1oq8s465792+oNtMuLZzwb/VSw/Uc3bfftLaXG17ue72Gn3O/ONXoVahm2w99Ojcwm06WCX358xwpdu5ajKMYiWE6ba6Xvu+pPIazCllOOBOpYqFFwi969O6qa0fXQ3Cgfw9HW4UZ4DQ1uMJLiMfB45tV3o5ynxprj84tYwSy4CXtl2deu6eIr714GFDSKvbzCcUY5BbA4XO14XPG45fa/mbzpQ1rsRL4tFkNHyUz5TVQLoGnUnSdnTYK9ynbOuy5wudTm3nWK3tKEd7q/OHDnQMIyQW44Rbts6wU4nS2Rd9I1gmUdi5eoOtYHFk2YAAAAAAABygEEzAAAAAAAAOcCgGQAAAAAAgBxA0wxyousQs2lN59zEYTDnRuV6I73bxPKi2AA73WhKW65CxaYmpWiYiaCiU/ZLcxmhd86Fuq6qb9bz3C65jxLNgm5JnLV8H/3xAZF3zEcnOGqrXD7WbJpxqe0CGZjKGjbC9HGZxQ6Qmtev9mRLpOKyWpH3yH+m2+lBb8vzfutbe4jl+OFj7HRoirQsdEeVcMOTxom81GeLjF5DG7T6WXXqWp6uVRYoWkTPrqwtJ/7xpzvs9IqE1MQGtXcnHv3dcXa69OuP22er1xVRdZua/dqaBmkXFtaWQ5oFnUrAw2UU9GjrKRLUoLIe0ZyQbadAeb/Eq2mRgx4ud5/W94YUC7xtUal51UkqmmbPKPnOCnBAqeepiLzOqVRPlsvvaqsuivC7AueXynDrKeWavUGTFE8JsB1dUrGdJVbEZX175M1D7LTvKHndr5zHGucC/brr5nXNdjhJ4kkzAAAAAAAAOcCgGQAAAAAAgBxAngG2a0o18cZQsbw49qGdXhVn+QVxYmGdWF6kzIzHNXmEjO8j8bdnTiUHuqxDXY6YvqxTvGsSfe30luQGkbfxqCo7XXG/nCYyE87ToD2KNkxte0rYlrB+xm4ir3C9nAP0buNa0v/RMpEXv5yn+TZu4siTxOjffMTbGDZE5CW0Yw3O50hmrr3Hirw1M5ToZJqSYBAHmuv5aFKAfG2cvMNl35GolNaA0QqWDWzeW7bBaCXvw/TIMvs8xlHr3m2UZTYmuEksl7+/nvdv9BzcE1hWRHjc3Fa8Qc3es0HaddXWs9zMr1nHjSplK8dIUpZJkS/qaDHn1SIEqvlhTbqhyj707SRMZyvSxhYpM1HZrf+mvK8vvZo8JUlT95PR+lJKuRCLwnzdO71GStdOrGR7zpT23HZqYIudvr5afu+6Cil5M318fCOfktLP5KKvHI+9LVammcCTZgAAAAAAAHKAQTMAAAAAAAA5wKAZAAAAAACAHEDTDLaLm0c965hX5pHKMY8SGjuTVthJI9XKRk5Z1ENjtxd9H+r+PZqtnX7cZW62yyt3S5uc2j1ZP1Wh77S72Vh1lGVhMukcZrkP61q9EZlXM1FaTDUcyGW27JCHRN60H//QTo9+SrMSU0isXpv12M3B/e10YJs8nnAV7//o01gnTXz+7kQ77frwc6Mn4/Jp5Rvl8nVPlLr01B1sDTi4mEPmEuvDUmt76aB37PQb9eNF3hUVb9npC78+U+T9t353O13qbRF525KF8li1Y9+e+u2iutxFhNEtg6XVXiTG59ZUQlhbaN2rey1rg6s1O7i65gLH6OmlIT7XMSUUN5FMyZVjWUJ11wZ4H0ntWFti3Pc2bJa/0R2SJz9UxBrrVXX83gkxcAjruBNr18kf0otxeX152aCeVjlHLA/xylDo91Rx/meadaSqU/86Vinyzl59kJ2e3kdqmPf69HSxPPqy2Xa61VsUnWgXiSfNAAAAAAAA5ACDZgAAAAAAAHKAQTMAAAAAAAA9RtOsC6hUdF2koqEU+slM67Y3lLHqTZqnL2kmXAHWVpmxWLfTvG5KSG/VMn91Fs2yPE+qVrgxJbXAxW7WxzWnpI9o0B139IeMaX7PHiUMq08Jv61/V/+eSqFbarK2JosctdsbkzIc+N+ms9b2d8YkozeSqw2KrCY+l1rRGk0HyXNb9RTXixlnynNbbDjrmNtCtD9rYGMlWqjWuayhnBXbT+QNCHKdCQ5iz1IjFTUMaeXd7ckW7jr1+WKx7D2bz8Wq9VJvbBhy+V5D9RqWeudLjAPs9K0rnxF5FR7uR/+45VCR9+Qs1kwSI5Z9lJf2Xs8zlPcz0tcN0+wigmbS21fI463ezP10qET6nV856U2xfNdLx9rp1CbZL5v9+bt+Ldx2U4TbYyzuzdrkU0ml73XJvjfg4/MY1bbTUM1975F7finyEim5nXdWcHh1X5GsW02TuB4GoWnOK3ZA5LipdnqfwPsi766t3B6JPUL8rsiEAHuhEwuiHGJ7WlDGLnjPz23+7JIakfd4oez/dxZ40gwAAAAAAEAOMGgGAAAAAACgx8gz2iJVUK3NckyZ5SvJWPfLaWL5nvP/YqdvHTUh/2Nrw9RmVyV14J52eoo2TfN1gqfPKjxsL0XUp2RZVHh5Oq06weGTCZ8r4Sjz8ChhtOOmN2/ruKQ236+G8HRrtnKqrEOXh6h5xAQ/2+3UadZKYe27vZI2tN3kVg6HWvD8JyJvxPPO33MXF4vlVFNTfvvXZV/auk1VXPcCtTLPX8dTmUNfkJZLLUP5eKJjOJx8IhHpcfKMtpBYv8Ex/HZr67r8+sZLF0vLuXcmPmmnlzVKo8cx+60Sy/E8w+tmy/Om5TddSHrTUiHrdaCQr3M37/EfkTdFCV1MPD1psp3e9FGVlCSN4zDa1Q1SphZT7OHcmlVdPC7L2ufn8+n1yHWLA1zuw0tleOTZ6/k6UR2R+//DsOfEcl8/S70+3DJC5FVP5Lo25EWR1bvJ0ldu+C7XIZ/Wb6qSSeKL8BA7XZ2QfXNTMphRhknURGWZqlQ/z9sk6h/ifnXMBXOcf0eOPr6t4EkzAAAAAAAAOcCgGQAAAAAAgBxg0AwAAAAAAECP0TS3IUxiW6zjtlzKWuW6CVK39sfDnrLTmxJbRd6n4ZF2uuZF1RrJMPod91Xe+3cHWd/z9Y2sFSZGXS1D83YVUj6+1wpqobFVDfEQr9QkRk2pLVJDYBd7Whzz/JpVnAidrWifCbemW1b1x3rI7VgWaZNqT9fK8s4l9VvNKd5QRNNYHxXic3Cn8+5AW8NvU77H2SZQzcumR22LNtTXpFUYtap5tDDBxbx/d4K/l9LaS69D9NupvDXMqjWo3sebT0rdcmAS69C9mrb21P6fiuUniznMd6pRvoMh2HcPsdj/TtZGf/6tnVsyHDWM7xpdgqrbPhTLnnF8jfrjnTNEXtHlsk6uu4jPp2u0tPlqivqddco+bp8pLfy1mqdXg2hMtvO6Fra5GxhiDTWxz8RldrrxVFknjvrlj8VycCBrmoedvULkFYXlcm+lVR+bpa/83d6shZ8XLRN5Rxd/IZarlPD1xVqfV5eSbVJlcbG0p1Ppf4+s0y5l7JZ4Y6jI805fwwsIow0AAAAAAMCOBYNmAAAAAAAAurU8I4sEI9sjd9ee4+308jOkldnIvTlSDfH2rrfb6ScapMzi9TreztrmPiLv6MqFdvpfezzsGK0qFxsu2stOj9pLmVLowmzZm+UKRe6Ao+WbbktTr8gY9GiCw30y+k9DimUrOuo+stnIWSi79OgRAZV1dcmFvuxkh0f09/A04YqojKC1JsHTi7EZe4s8/2tyqhhIcskq1HxTm1pvFcEt335FIxHi9LTvfCby3nqToxDu8qjcv7+R65q3Wfkd2yEV6RG0c6q0VVRJhbLHpYztixs5at3wQimr+yoyUCzXnsB9fPFqKQ85/6+qhZmMXDYhwN5yP/u/bzQZiVTUkPEPuw7JRSwZLJiRLU6rYZQtqrTTI/eR18svN/H502P0ZnP5crtlubtdvOzxy+n6+kbuQyNl0m7U7+ajTWzcJPJGXy6XVZwFAb0bU7smq6QOkFFWTyvi/u+pRjkeKlei4hLVSb4mPh8eLfLOKuFWMkuxpiMiKT2KMHPp11L2+sAxo3g7174g8mZ0YvRdPGkGAAAAAAAgBxg0AwAAAAAAkAMMmgEAAAAAANgpmmY1PGoq6Wixloqw9qyt+jdPf9ZdLf3jIJH37AEP2On1SdbNEm83sMUQ8bMNh9npIo/UtFX4ORTvWyukLifcjzU7Mx+/WuQNN6TGzjuMdTsrz5Yank8vustOn3LMOSIvdhiHM/X+b67RVVCd43wuaTukhrVuzKKX0nFroakbU6xrK/c0aVZxHsfwnXEl75vjc9ZCqnpnPfx2uZvrwpKkImylkMneWrEccPkc7en6uvl8NFwmQy33e83oOXRwqNLtRdU7Z9M359JNBxVJ7H8XjRN5/Scp4YfrpKa5bhfunwa+w/XXTOZvh9nr6oW+rmpVpdnTZeOVxgl2emRBtcibEJQa3ZtuXWCnk9o+Po5m7o+Ii5dy6O6CFSut/wnT+T2IHY52LoU9o2bVqFv99ZvH/dSW02UIZFPp/F2anZ9qK5dIyH2kUrrI2XC0BVT3sTVSKPIOqFhup6sNZ/3r9rb7XoM2PlNZc5Ss800pHq/VadfE6qSsJyHl+jkysFnk9fHwd9+tl++RTS5enXF/xPGyKhjX/F4en8q6Z/ldhcGn8PtnHQGeNAMAAAAAAJADDJoBAAAAAADYIfIMfSrI7XKcVcspyVBoPnUfO73xRDmt+cqBf7bT8yKDRd69W1hy0ZKUUzjDQ9KCaI+idXZ6S1za022K8vLZ4z4RebNrh9vpM497R+TNOHOB3E6Soxjdv+YQkXfS0P3stKdIRsMJ1rG0pCtNJvmajLzs2Oo1+5gGM+AoyfBnMQXSpRueVmZH7cOt7FOffg256h1t7Pp65DTsV3Ge4vK75HbqUnw+igM9eGp+J8sxstGWqdjUwTIqZ8V8jojW/4EvRd62s6bY6U0nsRyDUByXDGPpSuVgenAd6Oh6kWXqOBv/m8DzuNO/lLKZwwvkNve64WI7HS+R/cqfLmKZ3xBvncjb+jZbrw02lPLtKuhRctU2kMW+j/DUS/swFTUKYCAg+0FVkuHx6JILw9FyLqVFig0Eebu1YU0ikFCvIan8bQq7cP+0o1FlK3rf6A6xdOKOMx4ReTdW72unL+z7vsgrVcZ8ur3s8iw2ckvr+ovl08o/cZR+Lo/LgceiaU/Y6eeai0Te7/Z43k7f/L3vZbWobCt40gwAAAAAAEAOMGgGAAAAAAAgBxg0AwAAAAAAsEM0zdn0U1lY85tpYvmyM14UyweG7s5oI0TcteVwR93yPiUrHPepWqIRKSUMs25PlkixpuazeqmbHloobcdUrll2ilgOHLlKWWINNbH8NtY0//Xkv4i8F+s4FOSi89nuyp2MGsYXrNnZ0ZxzySxHW5jmVF87Xe5mPSgx0d/iaA+natx2FH6lvLdpdUhV6/XVLO+KVSssCp2dZD3VAI+0lduQZA3e27urYXkNY4ZL0c9Cc7fDdHsqK2/m9kfE+8g+YOyfuTw3XD5V5AW3cpkNeHqpyEuMHZrxPY5UV7Il6+J2dC4fC8PNRDzvmM3PrmXN4rK4zJtRxe/JEBWaPahK3QWs7wy65P6HP766S75vkg8ur+zrzLjU2ZsBzo8mpW44Fee+zxuSeS2K3jnol+0onpT6VLW/T6Rkf1oUZLuylpg81tfXjLXTVcYiIyvCsrB9+vieSLb+cOkfeJx1TOhDkbcowu8HvNi0u8i7sFSGuC72crtblcjfLlIdn3kNWWdiyliN2Jjg63KZW+ZtVa7JNUfKMUqshMedlffK35gPeNIMAAAAAABADjBoBgAAAAAAIAcYNAMAAAAAANBZmubkoXvZ6TVHSv9dzy6sNSnQvGknVm6w01OC74m8peEBYvmdbRxicUSh9Fcu87JedpcCqTlNKvcCG2NlIq/YE3H0AI5ofoIFih9vXNPT1ERZM7MtJkNK/nqU1GZ7lrN+a5hXal5nNfPverxaarz7B3jdJT/k/aVavIZxpbHTOL2Y/Wq3aXIlNeS17mf8n6aRYrlKCUftUWNaZwhr3dnoXtB1KW4aw33bRF7I7XM81oCmiw8pvtXPNpXLnULHvEN0e57xu4q81Tdw2RZ4pP9uvEbGal1xRh87XbpMq6NKNUiNqBJ57ijvv9uUsqINFmGXrQ/c+fnhboe/ctbtZmkrU+ZLjebZK46z080HyTDa2XAHg2JZ1TH/p36yyEusk576PYnwcL5mRuPyeuUNOOthi0KsRY4lsg8tVG9mv1duMxr3Or7ron7PM2aUyEt+xSG2c8WL6FW4PXm3z/tmPmqnF8bkO0gzi/i6vzwur2W3bJX+9ueWzbbTE/xyDPhsE3ucV4akj7oMzy33n9LGBAO9PCZarb3z8Mv5J9rpXb433+hI8KQZAAAAAACAHGDQDAAAAAAAQEfKM9b9bB/DE/hmCmuvmWz3sntAyiM8SnjLhoQMg1no5SmczUqY6kxT5FUF9Y62NGsjPG26zKwQeUFFFqDaxhF9/WHHffbxybyAm7dT4ZeP/8t9zY6Sj6+jUmYSMXked4E2WRtOsa1SP+08Dg/WGF0Bz2gpqxjo/cxOz43KqZcqTzijxIGIaXZ/quWbLn+ReR5HW5pCV8zxezpqOXxzPB7H721Tpol29ckpykZteqs6wSGUR/u4zhLNSr09VpMYPWjI89qVbdvaGo66M/avSwTcBTydnmyQZWRMZeuk1B+kvCa8gqcHBwyS1pEDLlgit5NFFqCG3K4fI8O49nmTbS93uNmVasGmH3+2PGV5R5d1RrJMIze/ym3n38ukPG7IqTLceb5T1S6/X5OPcVv+92K2/yRGGtwHdjtyaBU27afYfmkyC79iJedxy+1EFHu4wqDsl3XruKTSL6oWc0RDC7drr7YPdd3YoFKR55GuZxTLm9NdoT53JtnadZZ2VHe2tNw8KsT1enFMbmeAcjp30a5zw31zxfIfNh9hp0u8cnx0Yhmv63fLY1scYZlbomiLyIto4wCVp2qlleTw078wOgs8aQYAAAAAACAHGDQDAAAAAACQAwyaAQAAAAAA6EhN87CHlxte9ze6r/VzdrE//3R/qVcyxrI2d9Igac0zrIB1neNCbD9HFLqltkm1gPMp1l3ElCLWwuwTXCvy4oo1SVCzrCnVNG0hF+vYfC5nzcwaJWQjsTbBOrq6lNTUNacCjqG6qxNSx12qaIDXR6U9Xm2C7a+GvMKfk7uKDMbduWya3t8xL6LplMvcXE71CWkRUxMvFsuTghyKtsGU5yypnDM99Hk2O7qOsqpTy3RDUmqydI31SD9rr0JaSN9q5dgDLq2ddHGy6lr1EMitvmx2+P51jbOqY9Z198t+zMfnfp9DWhMVk/ldgZKjpU1Vm1DklimPPB9mvaax3pFkCTHd3nJxTWGNOLH0fH5XZdzvZD+eWJuld1L7X01r6S6Udn+pZn5v5Os/Sc3iEX1Zs7jqKGlNlZUs+k7dOi+ovOfgWiXfzRHY59jVLfwFW1kEasRHKP1dQj5XKyzga3TQl3DUNOs2crGEx1HTrFOo2NQ2tsjrQlB5t2jrbtIisPItbUOpblAYHUU72/VxP5Un7dkmHp88uXm6yJtevthOV3ilVdwpRbK/+8tgDk///+qd3/H627D/ibyoyfWmOil18cWKheA3KO+D+eT4zDBk3chb/50HeNIMAAAAAABADjBoBgAAAAAAoEMjAtLj8W8fkRfM/tr+eNhr0n5EpT4kpQvvj59ip2vHSpumxmHy8XtkIE8jmQFtSkld1a1brHCmd6ucEvc2y30EFDeqQJ3cTrCO9xnYJqcKPE08TeVuzD49aAb9+U1rb5AWK0vreKqiwPzETidMaX/X2SjOe63YmpRl6FOi/+jRnMYVSKmOX5nfbtQkD6ocR7WGs76nTJv6NKu45pScRtXznbaTMuKOkYmqk8VZohYZxsQA/66gJvFpNqWNVY+hs6IZZpk6yyYXWXajrIfJTVxGvvFy6rDPMdx3bQ8uZfo30k+261RESno6G1cgYLi+lf+4lHNoJqVllxmPOUoeHj/mfjv9TtNu2h64/yHuLWXbqLcPZqke8a/d5HSsozxC6wtVOQbh2ZW3e+3050XeM2ccqizxtDHhLub2mmpszNtyzt1fWpeqNphV72eTKqXXc3ddeUYWWYzLJ/uoyn7cXsJRmWcqEfmyCbSKfNkt5xJJPrce7ToRUfLc2rVdjRbYMFrWbTb+zE+G0lsjAManc3TLX5Q/JPLmxnjdG4e8IPIWxNiq8z81HBGa+OcWuc8hBWzleX3/D0XeCqUpXbJebceGcWfVO3a6zC2Hp9u0Jhg3+ViXh2XbNQyt3XfgtQtPmgEAAAAAAMgBBs0AAAAAAADkAINmAAAAAAAAOlLTnNxSbevmPGUcwtI7crhYz2xlDcK4t9TZ6fJl0pqoX6HUippaiGYVl9fjrFFRwmeaIc16RP2epZVmrVXKr9nihDgvVqJpsgawFU6sWFrFKU55rTTBWmRpIxHic+Vr7Ct/Rpx/V8lK1kiaiYhhfCw1fp1J/1fXyA9u4GRKu++KKyFa9bDVum1gs5Kva6ODrrjjPkLucEZbqEz79Cgiw2zaaHV/OvpxhzRrxGIl1GtYq4uq3aDwKOsOZLEr8/SXCsLUELncPITtw0L/mZ3/PtugN1t21758qElZJkPGbbLTgSNX5b1NXd/ppAe2lr18fiLlO1fMakajhun6pn7leyRjd5dWnfsHua4mjaUiz68FA/+ghfv8fQtWirwHzz7JTpc99lGWg85+pMOf4OvDTR8fI/LGfC7D9qq00jHnSXSo7H/XK/aggVlzjO6MS7km61G0Pf3k766uZU34gL7yfYDaZn5npKJQatC3KJaieohtHa8n5fjui0/JMxXdKuH38nLRCOd3qXLp5zvtnYwdpFV2qSHCdf12FltFouoGttmsTcn3sVImj5eqTTkemxnabKdP0azi9O08WMua53u2TRR5BxRx33J83/ki745te9jpC/vINh7Xru1NKe7zVzaUi7xANk3zdoInzQAAAAAAAOQAg2YAAAAAAAA61HJOIVmnTI2o6RyodkCugDYVqltKlfG6ZoFcN+V3PnTT63aUirgSztNGpkfeQ7iUKRx/nZyaDa0KO079mD5t6kQ9Vn3/yrHqee5G3kdyGU+Bunaw5dy6U4c55un2a3Up/g1TFekL8UEk7Bh1T5VK6NEh1eiAeqTIOk3y4NOmkdUIgUHNO0+dctYjCRZ7WhyjOOrbCSrlH9Gm/aQkpJvJM7JMYYYnyzrRMFS2x0CDIuUoKXGM5NcW9Kh/k/dm67g+flm3Vk1tQ5Q4FW3uOqttlbJqfLCzlGxH0HLMZMPrC7Yqi4EPf+5o6zatfIXj9pZEq8Tyl82DxHJNlOVU64rl1OhV1z5lpx95zLnv0Em8ISM3Xl7B21n9KykhyGIA126ifWR/tSHRp03SBxfZsXXVJm7b4rUmtgtbiRHFhdx29B5AjchX6Is62tEVaXkhv5RJNitWdinle0RpgKWI1UpUXD2yYEyxn0vbLorjiUad5QzZop3uTJRriVv7PaqNpZlDgqGy6nf7ieVHB99mp3+w4hSRd+fwZ+10WJMzLo3zctAly7dUswY8rGiRnd436BxpecId3xfL0b05st+vDloi8lbE5W8OKWO7DVtZLkyMMDoPPGkGAAAAAAAgBxg0AwAAAAAAkAMMmgEAAAAAAOgsTXN7EXZAuVxB2DWq3bi2Y91s390RATq7ShBQ7+E1jnmNSRm2elvK76gruvKmS8XyC79lbVWpW2rWVyaSGcPZEnVKqGzdYk7XRqtaZWn/ZhgxpYDL3VIDW6FomseEpK7uvDUHiuUTh75npxfHpLY2G97hrOFMrNJs/TpDK5fWy+Vrt5TFpkm34NKDmHZKPX5QhqY+qz/bmf353NNEnsv4rF27aKV1zBL2Xg2jvdeo1SKv8wyPMtMw3Gt4At905+/+5Hb78zcu7y/WWx3rZ6enK7pDYo3y25uSUoN6bJk8n0eGWNsa1d6xCHxrS0r84oHviLxdH2JNdeRmaVn2yOgnxPL3Fp9tpwvXO+uvO4qmgVJ7uSwiz50T5rf1wOyONmZk9zlelnX/4i12en291IpWlfD7CM1xqbn1KHZwQY+sE2XBFkdNc0tc9uFDizkEc3Pc7/i9goB8j8BTwXWbSKxbn5emu0uh1CFVw6zj8mp67rEccn7JFfwuGLHymPvF8mXrD7fTU/tIO86rVrHG+ZdDXxJ5w718vus07b4u5Y8Zzjrmfa652E5XPSZDbDe9Kt9bybZNtUTjDc5WoR1tN9hNahIAAAAAAAA7DwyaAQAAAAAAyAEGzQAAAAAAAHQ1TTPofhT4pM5zZZy9FIf4t4q8uObtqNL3YRlSd9qUH9vpPx/xmMgb6d1mpydpfpVvtrBGqVwJqZ2JmHJfqGuaG1Ks5Rvhl/q4qKJ7+slGDglKfPng7nInN7GmOa7dh0rNtdT5rTltsJ2uurWTNc3W72mjliub9kvTiQXelvrPA8vZQ/kf988QeZX3Sh2bE8tv5zDZxOIx94rlMa9cxOkPPjV2NGoY7TFFrAMl5u7g5xH9751teL/VEl975iH25z+qlOFuJwQ22umI1lbfDnNo7MFaux7nZ50pMVfRllZ4ZNtxG0p42+MflAd6PCc/icr2sFl7PyJ0o/T3ljtRjr0NnrXZiEn5rrGsWVXqc3/UivT+tZDP3YVoH9mWS/yspV0Vl/7YQ4u4HnxdL99k8HpTjn2t99sQ72kCyjWlXgnNTYwqrLbTG8OyDkQTPGTxeuT5jg+VmmaXqmnuhmy9QPor//vXt2WMDUBUerj/S2pe81/FpZ78qso37fR1648VeZcPfsNOP7F1msj7aeVbdjqkyYTrU7IvOUiRyU+5ljXMRN/H5DhAxa+VaTZSipI6sEnq4lU62qMbT5oBAAAAAADIAQbNAAAAAAAA5ADyDJATfZJ+hI9D6C6Kt3+qY8zFn9jpe4yxeX/PXcgWcO6+WqhbLWy6odiC6XIDU7H0ub1GTkdrGxFLfQ1teukmTnq0s6WGA9+SlBZbA2as5YVbjU4lfNzedphlT5R/j79eTpF7tyghrhtYhkOYYZ7mSzXJvIaotK06q4TDN9dfIEOtz3+JZQCJ1WulVdvpLMl45uS7Rd55q6XMY+xlX/LxGJ1EFomKqdS1uoT8jYbhbBfV2Xywgc0e76yS5fJymDUIxZrN4oEFbD/l05rRau339XXz70vqp0j57hcxeR62JdXtSNnV+81j5GY+yGIbqE1B54u7MORogRovlT9kaU2lna7U5BlqH6SGJu+y6P2iQniY7MObFCs53a2rKlhnpz9cx+1YD7GtM7RQnr+1DVwP40p4ZmJEgOUZCwMyxHdzjGVBbpcsr1iptB0L5Pn7uxLekXxOf3H130Vec4qfca5I8jWYWCLkL/JZaNAlz0u5ck26a8jLIu/H646206f2k5K3FXGWyuwXlGG0B3ulPOKAL062030fcZZj6Oj2gyqRlMxLmiwL89dn2WgH2w3iSTMAAAAAAAA5wKAZAAAAAACAHGDQDAAAAAAAQA6gaQY5KT1H6leN+Zwc5JFiIp+irYqanVO9VA1hV9AT/quJ9XnTgvJcLYyx9qzcLTV/qz9hy7kRhtT2djSNQz2GJ/CNdrBpqKLv6yf1jIXFrASMx2X48Eitoo9NSY2ga4O0Cjp4K4dM9y6U2wkoLkf1+0jbqkPHsE75J8tlCGb/T6WOLxXhMNDukKZVDecfzry9eJq5PF9/Z5LIG2V8bOwsKm7lcvI9LfWiR4fYMsytPTNZo1SFpXHpv1aXlGUY93A9L1b0zd8s83nxaWrzoIvzhnmlpvrXvz1YLIeM2Zkt5rbDZs6VJSx6MiA1snU1XN8qc9hYdWs0eXhTjPuAkKZdrU8UOGqRVRu5gUF5XZgQkv3be6lRdtrncy5Lr1seXDzJdTbolX2XJnHObjtmdE1Wn1ZlpycFNoi8t8McKnuIT76Do6qWKzzymhh0yfOrWk321c7E7wfNstOztHcMblnN75v8eCRb0xGnFDXI68hRzmHv1b5a76cbwvIdDJUyj3OfHtrcaW+1tAJPmgEAAAAAAMgBBs0AAAAAAADkAPIMkJPkZhntbObhPG1+5YvPibzRPp7+nTLn+yJvoLG4fQegTc2qU20uj7zvM7NFsVPt5zTMZNJ5+lef0tX28cs5bK/zxcF/EXmjfGyfdMzSk0TeiF/kb8XTkRHj8sU7iKcKidhIjvoXqZA2Ro2DpX2Y6eLl5iHaFP1UriNjiqSc5b23JtjpXR7lc0ckl7IcQ2dHyDF0PM1sefT8qTLy3Y9/KqN57UhUq7YZVVI20vBdnmI96GdSQnJLf/7eqFZT5nL6VeLPsZyZC9ZKC8HQvxU5RifRqp0r7Ln3MrG8eEt/5+1k62e6Ge6Y7EPjirVZUIsGu6CW+wRTWY+IxLh/KfJIWUfElHWivp6n6P1BTbYW7ecYSTCl7VPF25JoV7l3JYbcu8BOX3vc8bK9DHjHTo/0SvmLepZ0u8iIKT+IK9EaNyR1+RSnzypmC0pi37EsudjNJ68lB156ibO0SsOMyQiiKglN8qPSqETwtfbh5jL1NznLM1w+Ocw14877zwc8aQYAAAAAACAHGDQDAAAAAACQAwyaAQAAAAAAyAE0zaDNJBd/7WgDo4bYntR/vcjbrG3HU8a2Vsm6LHEwNXspU1k2nSO3dhguLUSorokKLmAbpqaD5AENU1pY/UNDRF6JIc9PVyOxXloeuZVlPWi0vtzuEO3KOenqKsTkwqV2+rgXrhR5o7No+nYmJU+yjvmzJ2XeDIP1z67J40Xe5n00C7rdWT9aNFDq0geVcls2NT3l8s2sVx11ZpYw2dZBuLbbYq4t2veN97ANGjHsC7b10vdutki7vO5M2SgZ4npIMYfKDiekFnlkUQ2ni6XtWYliIbh3obQcG61ZpM0axu8u7Fkm7eiuq+B3Fy6LFYu8fkVsp+bWe49oV+8xcqOGda/dX+bdPuZEO/31D6QJ4jGHz7HT1/d/T+QNdfP1aXuocHM7P+insr8r+U/HWGy6VihXEulAaYzzyTHC3xuH2eniT9eJPFXdbsadte7tAU+aAQAAAAAAyAEGzQAAAAAAAOQA8gzQdpRp0wvuvkJkBbfxlFnReilj8BpzxXKquZtMcZrZow0Fq/k3b0pKy5w6xSZHc08CPYjRP+qacoz2Ys5dKJYrZdNtFSFPfDdL3ihjXRsOohNs3bJss+hpWYbZJvvNRMdO+XY6WSzXmj4rF8tzysvsdKBaDhFWRkfY6WCNPJdq4LlXBrK1IREZIPff9zN+Xrc6IGUxTwzheXk9fqMnrHwygaUMxMjV0hpVlFA3sZzLRvKr5XZ65M84TahmrqcZ0u5Sl1rVj2HJS6SPfG5asI0vUiVL5fk153OfUNJJEU+HX8s2rAd+epHIC22U4wXvZpZrJNavdtzm9lrM6eBJMwAAAAAAADnAoBkAAAAAAICOkGekox8ljHj2uTewQ7DKoQOjUrW9fHmKLBmNiJxkjDeQSGjTIprVhUt5s97cETYY7cSlnWfTlFOzyRifg6ZGqcFoTvFyIi7PVSLDb975ZQs6E5Rvz6Url63ah+n9Vyoi+6VUC0sZkhFtiBDL3Ndb+1AUEMmoy3Gb33yXn9cltYirqYjpKM8w1O2Gtf40FXPsX3P14d29fLPhSsrojMm4L2M5WMcSV65X2vc66hrtylIX5bFo5ZuQy0YqmvVa2lnl6zLzqAHr1q0zhgyRdllg57N27Vpj8ODB270dlG/XA2Xbs0H59lxQtj0blG/vLt+8Bs2pVMrYsGGDUVxcbLi0u0Kw46Eia2xsNKqqqgy3e/sVNijfrgPKtmeD8u25oGx7Nijfnk2+5ZvXoBkAAAAAAIDeDF4EBAAAAAAAIAcYNAMAAAAAAJADDJoBAAAAAADIAQbNAAAAAAAA5ACDZgAAAAAAAHKAQTMAAAAAAAA5wKAZAAAAAAAAIzv/HwFnz8hH4VkiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x300 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root = \"../data\",train = True,transform=trans,download = True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\",train=False,download=True,transform=trans)\n",
    "\n",
    "print(len(mnist_train),len(mnist_test))\n",
    "print(mnist_train[0][0].shape) #第一个维度指定feature,第二个维度指定第几个\n",
    "\n",
    "def show_labels(labels):\n",
    "    name_labels = ['t-shirt','trousers','pullover','dress','coat','sandel','shirt','sneaker','bag','ankle boot']\n",
    "    return [name_labels[int(i)] for i in labels] # 要写int 不然不能正确索引\n",
    "\n",
    "def show_images(images,num_rows,num_cols,scale=1.5,labels=None):\n",
    "    figure_size = [num_cols*scale,num_rows*scale]\n",
    "    _,axes = plt.subplots(nrows=num_rows,ncols=num_cols,figsize=figure_size)\n",
    "    axes = axes.flatten()\n",
    "    for i,(axe,image) in enumerate(zip(axes,images)):\n",
    "        if torch.is_tensor(image):\n",
    "            axe.imshow(image.numpy())\n",
    "        else:\n",
    "            axe.imshow(image)\n",
    "        axe.axes.get_xaxis().set_visible(False)\n",
    "        axe.axes.get_yaxis().set_visible(False)\n",
    "        if labels:\n",
    "            axe.set_title(labels[i])\n",
    "\n",
    "X,y = next(iter(data.DataLoader(mnist_train,batch_size=12)))\n",
    "print(X.shape) # 12*1*28*28\n",
    "show_images(X.squeeze(),num_rows=2,num_cols=6,labels=show_labels(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape的规则说一下"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l_pytorch_pure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
